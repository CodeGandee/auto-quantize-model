# é‡åŒ–æ•æ„Ÿå±‚åˆ†ææ–¹æ³•åŠå·¥å…·-è°ƒç ”V1.0

## ä¸€. ä»€ä¹ˆæ˜¯â€œé‡åŒ–æ•æ„Ÿå±‚åˆ†æâ€ï¼Ÿ

é‡åŒ–æ•æ„Ÿå±‚åˆ†æï¼ˆQuantization Sensitivity Analysisï¼‰çš„æ ¸å¿ƒç›®çš„ï¼š
æ‰¾å‡ºæ¨¡å‹ä¸­å¯¹é‡åŒ–æœ€æ•æ„Ÿçš„å±‚ï¼ˆquantization-critical layersï¼‰ï¼Œä»è€Œæœ‰é’ˆå¯¹æ€§åœ°ï¼š
*   å†³å®šå“ªäº›å±‚ä¿ç•™ FP16 / INT8
*   å“ªäº›å±‚å¯ä»¥å®‰å…¨é‡åŒ–åˆ° INT4
*   æé«˜æ•´ç½‘é‡åŒ–åçš„ç²¾åº¦ã€ç¨³å®šæ€§ã€ååç‡

é€‚ç”¨äº Conv æ¨¡å‹ï¼ˆResNet/YOLOï¼‰ã€Transformerï¼ˆLLM/VLMï¼‰ã€NPU éƒ¨ç½²ã€‚

## äºŒ. æ–¹æ³•åˆ†ç±»

### 2.1 æ–¹æ³•ä¸€ï¼šæ¢¯åº¦/æŸå¤±æ•æ„Ÿåº¦ï¼ˆFIT / Fisher Informationï¼‰
*   **ä»£è¡¨ï¼š** FIT (Fisher Information Trace)ã€SQNR-basedã€gradient normã€loss jump
*   **åŸç†ï¼š** è¡¡é‡é‡åŒ–å™ªå£°å¯¹ Loss çš„å½±å“ã€‚å¸¸è§å®ç°ï¼šå¯¹æ¯å±‚è®¡ç®—åˆ†æ•°ï¼Œåˆ†æ•°è¶Šé«˜å±‚è¶Šæ•æ„Ÿã€‚
*   **ä¼˜ç‚¹ï¼š** å¿«ã€æˆæœ¬ä½ã€‚é€‚åˆ CNN / Transformerã€‚NVIDIA PTQ ä¸­æœ‰ç±»ä¼¼åº¦é‡ã€‚
*   **ç¼ºç‚¹ï¼š** ä¸€é˜¶è¿‘ä¼¼ï¼Œä¸å¦‚äºŒé˜¶æ–¹æ³•ç¨³å®šã€‚

### 2.2 æ–¹æ³•äºŒï¼šäºŒé˜¶ Hessian æ–¹æ³•ï¼ˆHAWQã€HAWQ-V2ã€Hessian Traceï¼‰
*   **ä»£è¡¨ï¼š** HAWQã€HAWQ-V2ã€Hessian-based PTQ
*   **åŸç†ï¼š** å¯¹é‡åŒ–å™ªå£° $\Delta W$ çš„æ•æ„Ÿåº¦è¿‘ä¼¼ä¸ºï¼š
    (æ­¤å¤„åŸæ–‡æœ‰å…¬å¼å›¾ç‰‡ï¼Œé€šå¸¸æ¶‰åŠ Hessian çŸ©é˜µ)
    ç”¨ Hutchinson + Power Iteration å¾—åˆ°å±‚çš„ Hessian æœ€å¤§ç‰¹å¾å€¼ $\lambda_{max}$ ä½œä¸ºæ•æ„Ÿåº¦æ’åºã€‚
*   **ä¼˜ç‚¹ï¼š** å‡†ç¡®åº¦æœ€é«˜ã€‚èƒ½ç¨³å®šæ”¯æŒ INT4ã€INT3ã€INT2ã€‚
*   **ç¼ºç‚¹ï¼š** è®¡ç®—é‡å¤§ï¼ˆéœ€ HVPï¼‰ã€‚

### 2.3 æ–¹æ³•ä¸‰ï¼šæ ¡å‡†é›†æ¨¡æ‹Ÿé‡åŒ–ï¼ˆSimulated Quantization, SQï¼‰
*   **ä»£è¡¨ï¼š** TensorRT PTQã€QATã€AutoQã€BRECQ å‰ä¼ æ¨¡æ‹Ÿ
*   **åŸç†ï¼š** ç”¨æ ¡å‡†æ•°æ®å¯¹æ¯å±‚æ’å…¥ FakeQuantï¼Œè§‚æµ‹è¾“å‡ºè¯¯å·®ï¼ˆMSE/KL/ACT è·ç¦»ï¼‰ã€‚
*   **å¸¸ç”¨æŒ‡æ ‡ï¼š**
    *   Activation Cosine Distance
    *   MSE (per-tensor / per-channel)
    *   KL Divergence
*   **ä¼˜ç‚¹ï¼š** ç›´æ¥ä½œç”¨è¾“å‡ºï¼Œå·¥ç¨‹ä¸Šæœ€å¸¸ç”¨ã€‚NVIDIA TensorRT å®˜æ–¹æ”¯æŒã€‚
*   **ç¼ºç‚¹ï¼š** éœ€è¦å®Œæ•´å‰å‘æ¨ç†ã€‚

### 2.4 æ–¹æ³•å››ï¼šæ„ŸçŸ¥æƒå€¼é‡è¦æ€§ï¼ˆAWQ / GPTQ / QDropï¼‰
*   **é€‚ç”¨äºï¼š** LLM/CV-Transformer
*   **åŸç†ï¼š** é‡åŒ–è¯¯å·®æ”¾åœ¨â€œä¸é‡è¦â€çš„æƒå€¼ä¸Šã€‚
*   **å·¥å…·ï¼š**
    *   AWQï¼ˆActivation-aware weight quantizationï¼‰
    *   GPTQï¼ˆç¬¬äºŒé˜¶å—wiseæ‹Ÿåˆï¼‰
*   **ä¼˜ç‚¹ï¼š** æ˜¯ç›®å‰ LLM é‡åŒ–æœ€å¼ºæ–¹æ³•ï¼ˆINT4 å¯ä¿æŒæé«˜ç²¾åº¦ï¼‰ã€‚
*   **ç¼ºç‚¹ï¼š** å¯¹ CNN é€šç”¨æ€§ä¸€èˆ¬ã€‚

## ä¸‰. å·¥å…·

### ğŸŸ© NVIDIA å®˜æ–¹å·¥å…·é“¾ï¼ˆæœ€æ¨èï¼‰

#### 1. NVIDIA ModelOptï¼ˆ2024â€“2025 ä¸»æ¨é‡åŒ–æ¡†æ¶ï¼‰
*   **é€‚ç”¨äºï¼š** CNNã€Transformerã€LLM
*   **ç‰¹ç‚¹ï¼š**
    *   è‡ªåŠ¨æ•æ„Ÿåº¦åˆ†æ
    *   æ”¯æŒ INT8 / INT4 / FP8 / æ··åˆç²¾åº¦
    *   è¾“å‡ºå¯ç›´æ¥ç”¨äº TensorRT / NIM / Jetson / NPU
*   **åŠŸèƒ½ï¼š**
    *   `modelopt.quantization.auto_quantize()`
    *   `modelopt.quantization.sensitivity_analyzer`
*   **å¯ç”Ÿæˆï¼š**
    *   per-layer MSE
    *   per-layer Hessian metric
    *   per-layer mixed-precision suggestions

#### 2. TensorRT PTQ (Post-Training Quantization Tools)
*   **æ–¹æ³•ï¼š**
    *   per-layer MSE
    *   per-layer KL
    *   per-layer cosine similarity
    *   calibration cache
*   **è¾“å‡ºï¼š** INT8 engine
*   **å·¥å…·ï¼š** `trtexec --sparsity=enable --quantize=INT8 --layer-info`

#### 3. NVIDIA Tao Toolkit
*   è‡ªåŠ¨ PTQ + è‡ªå¸¦æ•æ„Ÿåº¦è¯„ä¼°
*   é€‚åˆä¼ä¸š GPU é‡äº§éƒ¨ç½²

### ğŸŸ§ PyTorch / Open-source å·¥å…·

#### 4. Intel Neural Compressor (formerly LPOT)
*   **åŸåï¼š** Intel Low Precision Optimization Tool (LPOT)
*   **ç‰¹ç‚¹ï¼š** 
    *   æ”¯æŒæ•°åç§æ•æ„Ÿåº¦åˆ†ææŒ‡æ ‡
    *   å…¼å®¹ PyTorch/ONNX/TensorFlow
    *   æä¾› per-layer sensitivity æŠ¥å‘Š
    *   **Accuracy-Aware Tuning:** è‡ªåŠ¨æ··åˆç²¾åº¦æœç´¢

#### 5. Microsoft NN-Tool / Olive
*   è‡ªåŠ¨é‡åŒ–æœç´¢
*   æœ‰ layer-wise sensitivity & MSE

#### 6. HAWQ / HAWQ-V2 å®˜æ–¹å®ç°
*   CNN + Transformer é€šç”¨
*   æ”¯æŒ INT8â€“INT2

#### 7. BRECQï¼ˆæœ€å¼º PTQï¼‰
*   è®¡ç®— layer-wise reconstruction error
*   æ¯” HAWQ æ›´ç²¾ç¡®

#### 8. GPTQ / AWQ
*   Transformer / LLM é‡åŒ–ä¸“ç”¨

## å››. ç»“è®ºä¸è½åœ°å»ºè®®ï¼ˆçŸ­æœŸ vs ä¸­æœŸï¼‰

*   **çŸ­æœŸï¼ˆå·¥ç¨‹å¯å¤ç°ï¼Œä½é£é™©ï¼‰ï¼š** ä½¿ç”¨ NVIDIA ModelOpt çš„ `auto_quantize` + SmoothQuant/AWQ æµç¨‹åš PTQï¼Œå†ç”¨ TensorRT-LLM éƒ¨ç½²ï¼›FIT ä½œä¸ºå¿«é€Ÿé›¶æ ·æœ¬æ•æ„Ÿåº¦ç­›é€‰å™¨ã€‚
*   **ä¸­æœŸï¼ˆè¿½æ±‚æè‡´ 4-bitï¼‰ï¼š** ç»“åˆ SVDQuant æˆ–ç¤¾åŒºé«˜æ€§èƒ½å®ç°ï¼ˆNunchaku ç­‰ï¼‰ï¼Œå¹¶åœ¨æ”¯æŒ NVFP4 çš„ GPU ä¸Šæµ‹è¯•æ€§èƒ½/ç²¾åº¦æŠ˜ä¸­ã€‚è‹¥ PTQ ä¸å¤Ÿå¥½ï¼Œå†åš QATã€‚

## å‚è€ƒè®ºæ–‡

*   **TensorRT Model Optimizer (ModelOpt) â€” API & auto_quantize.**
    *   [nvidia.github.io](https://nvidia.github.io/TensorRT-Model-Optimizer/reference/generated/modelopt.torch.quantization.model_quant.html)
*   **NVIDIA æŠ€æœ¯åšå®¢ï¼šOptimizing LLMs & NVFP4 ç›¸å…³æ–‡ç« ã€‚**
    *   [NVIDIA Developer](https://developer.nvidia.com/blog/optimizing-llms-for-performance-and-accuracy-with-post-training-quantization/)
*   **AWQ: Activation-aware Weight Quantization for LLM Compression and Accelerationã€‚**
    *   [arXiv:2306.00978](https://arxiv.org/abs/2306.00978)
*   **SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Modelsã€‚**
    *   [arXiv:2411.05007](https://arxiv.org/abs/2411.05007)
*   **HAWQï¼šHessian-Aware Quantizationï¼ˆåŸå§‹è®ºæ–‡ï¼‰ã€‚**
    *   [arXiv:1905.03696](https://arxiv.org/abs/1905.03696)
*   **FIT: A Metric for Model Sensitivityã€‚**
    *   [arXiv:2210.08502](https://arxiv.org/abs/2210.08502)
*   **SmoothQuantï¼ˆactivation-aware smoothing for PTQï¼‰ã€‚**
    *   [arXiv:2211.10438](https://arxiv.org/pdf/2211.10438)
