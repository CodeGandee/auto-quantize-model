{
  "scheme": {
    "name": "int8_autoquant_all_layers_int8",
    "auto_quantize_bits": 8.0,
    "auto_quantize_method": "gradient",
    "auto_quantize_score_size": 128,
    "coverage_mode": "full",
    "coverage_fraction": 1.0,
    "quant_formats": [
      "INT8_ALL_LAYERS_CFG"
    ]
  },
  "model": {
    "id": "models/qwen3_vl_4b_instruct/checkpoints/Qwen3-VL-4B-Instruct"
  },
  "autoquant_state": {
    "keys": [
      "candidate_stats",
      "best",
      "constraints"
    ],
    "constraints": {
      "effective_bits": 8.0
    },
    "score": 204565064.61774084,
    "is_satisfied": true
  },
  "layer_sensitivity": [
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 104279167.26103139,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 55570464.67352602,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 9133151.46857363,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 8776331.961640116,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 8511525.552711517,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 7113657.902573355,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.0.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 1690245.2960997783,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 1083341.2420252766,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.1.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 603144.3594846069,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 511788.5305556343,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.4.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 509406.1772854384,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.patch_embed.proj",
      "num_bits": 8.0,
      "sensitivity": 494208.77859678166,
      "size_cost": 786432.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 383115.5873724357,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 378026.14073534217,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 345219.93952005776,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 299599.9230027837,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 292228.2642268995,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 289206.928703425,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 267674.10779831535,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 242167.77200690052,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 236046.04652995826,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.merger.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 225966.86465827771,
      "size_cost": 8388608.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 190119.62542942096,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 179788.2153679859,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 175465.17270660005,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 146900.08210115414,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 137934.30038509518,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.blocks.2.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 119569.76803612197,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 116923.57371200994,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 100685.56586958491,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 100233.82377542742,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 97511.57168088492,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 92413.13796132151,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 91530.40809259797,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 89092.39921438368,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.5.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 79083.92101244553,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 73204.55982992146,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 72110.62140528904,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.2.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 70111.30438890017,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.0.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 65873.71686890454,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 59916.30570255476,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 59770.637853266904,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.blocks.1.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 58821.52072680229,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.5.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 56692.56242114247,
      "size_cost": 524288.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 51459.535219264915,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 50839.39238434867,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 49678.42154562601,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 48154.46156054578,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.4.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 43966.979824326,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.4.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 42208.14643223025,
      "size_cost": 524288.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 40443.44369198941,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.merger.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 35617.074873471516,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.visual.blocks.7.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 34624.909020040766,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.3.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 33352.130139497225,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 32528.085604132037,
      "size_cost": 8388608.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 30945.914662413357,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.6.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 30503.289267537533,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.8.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 27774.59612629935,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.3.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 27539.05971814852,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.6.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 25827.105480555998,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 20362.32748583355,
      "size_cost": 8388608.0
    },
    {
      "layer": "model.visual.blocks.7.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 18917.656644256727,
      "size_cost": 524288.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 18242.12564485427,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 16209.175191801274,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 15787.50827472753,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 15202.904101406632,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.9.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 13665.57874292793,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 13214.794507023063,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.11.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 13050.037821725971,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 12834.558361244577,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.12.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 12337.18616226947,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 12232.19136392232,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.blocks.9.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 12111.280236775186,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.8.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 12042.289622485434,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.10.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 11977.755662388692,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 11222.476402220767,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 10721.771914095967,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 9857.642701474833,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 9655.624297470262,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 8949.606726915663,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.12.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 8511.622959608882,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 8267.638169734433,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 8217.442523031961,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.10.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 7835.282666933781,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.11.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 7727.039552557573,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 6834.860572108853,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 6798.1727841665415,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 6328.725983810786,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 6230.857113283186,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.14.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 5705.3460398846655,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.13.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 5151.554061623276,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 5011.757805231129,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4570.081802658784,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4472.428429771655,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.visual.blocks.13.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 4340.759107736834,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 4334.993527316954,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4241.970063909621,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 4165.720665316621,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4085.7272502821397,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3781.54152906777,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 3766.9001309680752,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 3738.055502979587,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 3696.9597723707557,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3629.998384175953,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3555.661414511158,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.visual.blocks.21.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 3460.981638088051,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3403.736649512762,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 3376.433277163047,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 3313.1492838739578,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.visual.blocks.22.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 2993.4533215518677,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 2872.937138660338,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 2822.2497380988752,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.visual.blocks.23.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 2725.539165212562,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 2687.0304276714596,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 2546.0532771466387,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 2540.6793147135613,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2524.6997528858956,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 2435.8944790916794,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 2383.7569331748673,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.visual.blocks.14.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 2352.6200824926236,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.language_model.layers.4.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 2223.6588615293877,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.visual.blocks.18.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 1860.9096037438903,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.15.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 1842.2452717188316,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.16.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 1841.78067433885,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1795.9089042863197,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1727.284539840417,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.visual.blocks.17.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 1696.9323150690252,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.16.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 1584.9809951181196,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.19.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 1532.159536655001,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.20.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 1468.8491657329105,
      "size_cost": 524288.0
    },
    {
      "layer": "model.visual.blocks.19.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 1437.3914884763471,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.15.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 1404.098008924584,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.20.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 1330.885425520275,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.17.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 1315.5435532392949,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1236.595725578285,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1234.056181917118,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 1156.9253468604074,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 1104.7899748997952,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 1094.7322314750018,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 1057.3801895410434,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1014.0509040489269,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 959.8269902091679,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.visual.blocks.18.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 942.7290202236136,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 874.5118845956895,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 675.5569925205054,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 672.7238004895098,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 632.5442919609948,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 605.9178300628555,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 543.7481584732323,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 489.271140235036,
      "size_cost": 2097152.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc1",
      "num_bits": 8.0,
      "sensitivity": 488.22394349067326,
      "size_cost": 8388608.0
    },
    {
      "layer": "model.visual.blocks.21.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 477.8526633255078,
      "size_cost": 524288.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 470.85165545728705,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 414.07831805050046,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 407.8735185368687,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc2",
      "num_bits": 8.0,
      "sensitivity": 399.25509797544146,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 384.52603839623043,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 366.3671720758721,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 317.37400662351683,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 284.7677113745393,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.visual.blocks.22.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 284.5182035751941,
      "size_cost": 524288.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 264.6381566701457,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 238.3529149246324,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 230.3128136560381,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 221.65131914095036,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 209.21104156286697,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 174.50371628011317,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 173.06977301836014,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 157.3933532547071,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 121.74280312441988,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 100.18759198736478,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 89.68111369869848,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.visual.blocks.23.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 81.22097108098615,
      "size_cost": 524288.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 74.67854347647881,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 65.33515045502111,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 56.35921744017833,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 49.254874602658674,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 31.9206743621412,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 30.51856226844052,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 29.426260545915284,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 17.599578607005242,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 13.43872877076501,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 10.492392525076866,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 6.166565773746697,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.3046583966133767,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 2.3111856311006704,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.8052422630898945,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4765322648454458,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3610869042458944,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2540284837596118,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2184172412380576,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 1.1978412359021604,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 1.1150030749849975,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 1.0562887857668102,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.9023473305642256,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.8792253329884261,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.7811975863296539,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.7679338213056326,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.7640661497134715,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.7299759550951421,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.693579708924517,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.6875371991336579,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.6728859339091287,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.6468213382177055,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.6251214225267177,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.4893465210625436,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.45235953689552844,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.41134845340639004,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.3817154447315261,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.3594265292631462,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.2981624553867732,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.22019265713606728,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.20531051853322424,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.1347182562967646,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.13288760351133533,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.11739012981342967,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10958986946207006,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10374343168041378,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.08616048396652332,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.08448976340878289,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.08166934056498576,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.07899202367116231,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.07831817099213367,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.07582176808500662,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.07455381637555547,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.07273809909747797,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06387174102565041,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05854092733352445,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0509492671044427,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.04723363718949258,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03925435666315025,
      "size_cost": 24903680.0
    },
    {
      "layer": "lm_head",
      "num_bits": 8.0,
      "sensitivity": 0.0368813236564165,
      "size_cost": 194478080.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.02999149647075683,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.024681922659510747,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0238107733639481,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.021920293729635887,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.021335956564144,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.017747824826074066,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.01744089095882373,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.016508535540197045,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.014215414848877117,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.012796262330084573,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.012700826267973753,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.011749750206945464,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007550345060735708,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00747292361484142,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.006967980074477964,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.006931679390618228,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.006162802746985108,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 0.004751072132421541,
      "size_cost": 5242880.0
    }
  ]
}