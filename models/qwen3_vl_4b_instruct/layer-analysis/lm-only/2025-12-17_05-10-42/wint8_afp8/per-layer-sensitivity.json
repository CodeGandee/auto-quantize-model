{
  "scheme": {
    "name": "wint8_afp8_autoquant_lm",
    "auto_quantize_bits": 8.74530701482171,
    "auto_quantize_method": "gradient",
    "auto_quantize_score_size": 128,
    "coverage_mode": "lm_only",
    "coverage_fraction": 1.0,
    "quant_formats": [
      "INT8_WEIGHT_FP8_ACT_CFG"
    ]
  },
  "model": {
    "id": "/workspace/code/auto-quantize-model/models/qwen3_vl_4b_instruct/checkpoints/Qwen3-VL-4B-Instruct"
  },
  "autoquant_state": {
    "keys": [
      "candidate_stats",
      "best",
      "constraints"
    ],
    "constraints": {
      "effective_bits": 8.744307014821711
    },
    "score": 2.3840689998102356,
    "is_satisfied": true
  },
  "layer_sensitivity": [
    {
      "layer": "model.language_model.layers.4.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.28598752385005355,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.13859470677562058,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.4.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.1151291630230844,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.11378074483945966,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.11039671977050602,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10415396024473011,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.08150677243247628,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0656815484398976,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06525934766978025,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0639939671382308,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06398905813694,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06199961621314287,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06194987636990845,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.061822537682019174,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.061748669715598226,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06112365471199155,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06071657850407064,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05546258285176009,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.054091210244223475,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.047747240343596786,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.04381831572391093,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.04199127806350589,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.041811125818639994,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.04145766468718648,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03760456515010446,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03705494257155806,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03433498681988567,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.033881231443956494,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.032182900002226233,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03176324034575373,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.029417717567412183,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.027937570121139288,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.025460229255259037,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.020941651659086347,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.01971977250650525,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.01735122926766053,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.013251306139864028,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.012571199331432581,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.012527449609478936,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.01163704675855115,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.009743329224875197,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007854262774344534,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007419908419251442,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.006967590030399151,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.005806484536151402,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.005622309457976371,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.004455305366718676,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0043601884244708344,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.003747334732906893,
      "size_cost": 12451840.0
    },
    {
      "layer": "lm_head",
      "num_bits": 8.0,
      "sensitivity": 0.0036459819675656036,
      "size_cost": 194478080.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.003265712599386461,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.003053539912798442,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.002247077783977147,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.002154928253730759,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0016524582606507465,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0016446736481157131,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0013145067714503966,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0011410644074203447,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0008207211576518603,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0006581496636499651,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0005421457790362183,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0004850827090194798,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00046288774774438934,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00039231306664078147,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00035669745284394594,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00033521881596243475,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0003077940418734215,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0002772744910544134,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00024168876825569896,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00021506601660803426,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00021246150208753534,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00016778769622760592,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00011982804744548048,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.2384451579048346e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.9029938911785393e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.817310668883465e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.732554596856062e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.638826576311203e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.5461482334444554e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4763471007483986e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.452332389106914e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4119377524934862e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3685057595580474e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3530855433430133e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3043949323332527e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2815864252502251e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2621145884850193e-05,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.1904207710244918e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.1683532960660159e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.1393703431394897e-05,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.0783959034199597e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.0608322597249753e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 9.925392177478898e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 9.555137538086456e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 9.060329880128393e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.981659199491787e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.938423320614675e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.658596676980324e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.501408807148891e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.180734376139753e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.02305966374206e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.84478753246276e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.756181396700867e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.516082575875771e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.498402045058583e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.125564216892144e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.033362294350809e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.671346323372518e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.5259748893709e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.18473136423836e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.093094685548749e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.8436764927828335e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4.577373598380063e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4.34121014336597e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.022227940936318e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.937602130577034e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.8537760218559924e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.830405006510773e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.798820713996065e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.683280567656766e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.652799861697531e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.61242368285275e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.3870764468701964e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.3773239636047947e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.974381402509607e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.819237472806435e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.8096138038335994e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.5472877211996092e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.4627455630366057e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.462174734318978e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.3956031185434767e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.2435206474824554e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.1851822182838987e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.1488171952910307e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.1120694952969643e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.006534614906741e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.882222058213756e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.8728498289988238e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.8642779338051696e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.778141765385044e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.5104751938110894e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4159643342281925e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3773689602203376e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.365064093761248e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 8.591221529741233e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.visual.patch_embed.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.0.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.0.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.1.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.2.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.3.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.4.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.5.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.6.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.7.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.8.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.9.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.10.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.11.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.12.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.13.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.14.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.15.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.16.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.17.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.18.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.19.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.20.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.21.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.22.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.23.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.merger.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.merger.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    }
  ]
}