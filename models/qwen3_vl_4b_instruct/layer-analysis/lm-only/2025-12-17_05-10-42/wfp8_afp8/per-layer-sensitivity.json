{
  "scheme": {
    "name": "wfp8_afp8_autoquant_lm",
    "auto_quantize_bits": 8.74530701482171,
    "auto_quantize_method": "gradient",
    "auto_quantize_score_size": 128,
    "coverage_mode": "lm_only",
    "coverage_fraction": 1.0,
    "quant_formats": [
      "FP8_DEFAULT_CFG"
    ]
  },
  "model": {
    "id": "/workspace/code/auto-quantize-model/models/qwen3_vl_4b_instruct/checkpoints/Qwen3-VL-4B-Instruct"
  },
  "autoquant_state": {
    "keys": [
      "candidate_stats",
      "best",
      "constraints"
    ],
    "constraints": {
      "effective_bits": 8.744307014821711
    },
    "score": 3.9844110984614396,
    "is_satisfied": true
  },
  "layer_sensitivity": [
    {
      "layer": "model.language_model.layers.4.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.3424186110496521,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.2727905958890915,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.24157243128865957,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.1920071542263031,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.17112639406695962,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.4.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.15715900110080838,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.14455423853360116,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.13744077179580927,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.12040322506800294,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.11867723404429853,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.11270318483002484,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10947201889939606,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10654256609268486,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10518160881474614,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10413640015758574,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10385202965699136,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10123052960261703,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10062465805094689,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.08428694633767009,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.07919137785211205,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.07304093800485134,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0712536321952939,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.07021046569570899,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06679714052006602,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06633930350653827,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06436635856516659,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.057129240129143,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05365389189682901,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05271979235112667,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05124251963570714,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.049954522866755724,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.04884689720347524,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.046258024172857404,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03704354027286172,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03594121936475858,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03355946368537843,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.02210885373642668,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.021643140353262424,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.019369530607946217,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.016300325223710388,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.012446382781490684,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.011895869101863354,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.011570216505788267,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00960203529393766,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.008763310353970155,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00786073922063224,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007335871487157419,
      "size_cost": 12451840.0
    },
    {
      "layer": "lm_head",
      "num_bits": 8.0,
      "sensitivity": 0.006482637982117012,
      "size_cost": 194478080.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.006194941612193361,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.006072410076740198,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.004917651996947825,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.004083244457433466,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.003596626775106415,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.002970312983961776,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0027846039010910317,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0021862212088308297,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.001937469955009874,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0013193941267672926,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0012178167362435488,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0009638476149120834,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0009258713180315681,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0008605367493146332,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.000742419135349337,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0005439347260107752,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0005132111518832971,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0004295368398743449,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0004131032201257767,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00039957949320523767,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00036902261672366876,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00035306543668411905,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00030253421209636144,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00023711087669653352,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001306052577092487,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 5.6366775240235256e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.0953370213637754e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.422038444649388e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.4059594480263513e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.3755364509270294e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.3214870971344226e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.3069531337682747e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.2870720769674335e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.2057697336208548e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.199637737021476e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.0475190368074436e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.044546599933028e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.998438578709738e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.8739675013534907e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.858962859557778e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.8562931472843047e-05,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.7718596140525733e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.6870432887117204e-05,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.628506369399929e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.628212638848936e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.5730348536635574e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.5606731530226625e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.5523988068366634e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4426742040996032e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4101353691842178e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3914258929048628e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3699327375604753e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3526372370620265e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3417687796390965e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.335628244447662e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3268868144677981e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2139296508451025e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.1162086913429903e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.0096670997938872e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 9.769984529839348e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 9.068916625665224e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 8.248399211652213e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.013673546969358e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 7.944210210553138e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.812508819426967e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.321682311101085e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.633957269741586e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.563734302744706e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.513046997724814e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.427458743019088e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.369441550191368e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.228136300023834e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.199941722684343e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.0413554479055165e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.8515068701581185e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.420112131560018e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.939786464319695e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.889839601673884e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.83612934942812e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.207115296139818e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.927250205038035e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.925475667188039e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.838236764863723e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.8035493332699843e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.78511822418659e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.6067789608296152e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.3893341822022194e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.3725045796018094e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.2144542956302757e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.184669949973795e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.1718230388833035e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.030517277125e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.5845974178650977e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.4479508766717117e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.3559458028898916e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.3255644379105433e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4330030282394546e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.visual.patch_embed.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.0.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.0.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.1.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.2.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.3.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.4.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.5.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.6.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.7.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.8.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.9.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.10.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.11.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.12.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.13.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.14.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.15.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.16.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.17.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.18.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.19.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.20.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.21.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.22.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.23.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.merger.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.merger.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    }
  ]
}