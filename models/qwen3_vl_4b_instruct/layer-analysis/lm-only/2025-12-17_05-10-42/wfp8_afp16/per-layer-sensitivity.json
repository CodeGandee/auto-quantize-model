{
  "scheme": {
    "name": "wfp8_afp16_autoquant_lm",
    "auto_quantize_bits": 8.74530701482171,
    "auto_quantize_method": "gradient",
    "auto_quantize_score_size": 128,
    "coverage_mode": "lm_only",
    "coverage_fraction": 1.0,
    "quant_formats": [
      "FP8_WEIGHT_ONLY_CFG"
    ]
  },
  "model": {
    "id": "/workspace/code/auto-quantize-model/models/qwen3_vl_4b_instruct/checkpoints/Qwen3-VL-4B-Instruct"
  },
  "autoquant_state": {
    "keys": [
      "candidate_stats",
      "best",
      "constraints"
    ],
    "constraints": {
      "effective_bits": 8.744307014821711
    },
    "score": 2.0183544351049285,
    "is_satisfied": true
  },
  "layer_sensitivity": [
    {
      "layer": "model.language_model.layers.0.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.23188460525125265,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.4.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.15918904775753617,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10376606532372534,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10300622694194317,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.07875792682170868,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06957296293694526,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06916656927205622,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.4.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06448342651128769,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05740288272500038,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05532731208950281,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05290078540565446,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05247329734265804,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05212347861379385,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05194136104546487,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05161389021668583,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.05057760019553825,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.04898571193916723,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.04160975379636511,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03708039643242955,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.036650337278842926,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03645129315555096,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03509132273029536,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03497952606994659,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.034691341570578516,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03425506979692727,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.033880497445352376,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03226808691397309,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.028185730800032616,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.02796201000455767,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.025794144137762487,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.02519274258520454,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.023433701950125396,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.023018899548333138,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.019294468977022916,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.01709338411455974,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.016923991293879226,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.013174175110179931,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.010618827305734158,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.009550379327265546,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007203128538094461,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0063883896509651095,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00597319399821572,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.005340234347386286,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.004579375439789146,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00415322910703253,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00392325060965959,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0037060895265312865,
      "size_cost": 12451840.0
    },
    {
      "layer": "lm_head",
      "num_bits": 8.0,
      "sensitivity": 0.0036038013931829482,
      "size_cost": 194478080.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0034383888269076124,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.002842843998223543,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0025145706167677417,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.002112954265612643,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0018043554300675169,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0014764615152671468,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.001469578011892736,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.001058279383869376,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0009334680635220138,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0006695803494949359,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.000611131223195116,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0005550702644541161,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00044772118781111203,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0004182930861134082,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00035600494311438524,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0002774094837150187,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0002640454176798812,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0002614589452605287,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00021858623176740366,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00021505272252397845,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00020520146244962234,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001843678569457552,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00017432203912903788,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 9.368290875499952e-05,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 6.838829540356528e-05,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.833884787278862e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.632860043088158e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.504187190448647e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4483540976328868e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4004144709645061e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3798709161960687e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2973185192777237e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2808297611854869e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2391532905553504e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2298569458835118e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2117193573857321e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.004061993370442e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 9.799721347292234e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 9.680711173132295e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 9.449455511401084e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 9.33978472517083e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 8.858384916266004e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.449446262659421e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.41527257477992e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.321014227874457e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.168692978927083e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.933325910869371e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.830823971488599e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.172698460067295e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.12763629451274e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.021934678164143e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.988726624967967e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.8344624182259395e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.582550536649023e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.542237372286763e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.18312326139403e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 5.789525364008341e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 5.662073085943575e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 5.114031818465037e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4.8194382316069095e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4.577327260335551e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.554691400926458e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4.377215141460056e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.173740322244157e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.989075324284386e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.803439934557673e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.373919497562383e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.328797475887768e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.280471560174192e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.195696024249628e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.077328301515081e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.028320719522526e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.0244526811884498e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.007300819035663e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.968324857022253e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.702900495421545e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.4954122537224066e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.4436178449604995e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.4250896402122635e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.123045533153345e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.9592858322425855e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.9513128961534676e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.915616856251745e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.8986831449296915e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.8585701795359455e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.825570222990791e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.6866336451926145e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.6611663582466463e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.6309284376347932e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.5857452595469113e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.5744662178462931e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.5108226634197308e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3207884315136198e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2327036138515268e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.170843248132769e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.1442056830901493e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 7.07534031363366e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.visual.patch_embed.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.0.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.0.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.1.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.2.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.3.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.4.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.5.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.6.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.7.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.8.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.9.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.10.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.11.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.12.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.13.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.14.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.15.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.16.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.17.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.18.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.19.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.20.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.21.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.22.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.23.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.merger.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.merger.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    }
  ]
}