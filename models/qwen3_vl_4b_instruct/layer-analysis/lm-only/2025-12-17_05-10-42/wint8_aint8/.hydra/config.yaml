model:
  name: qwen3_vl_4b_instruct
  family: qwen
  variant: 3-vl-4b-instruct
  format: pytorch
  path: ${hydra:runtime.cwd}/models/qwen3_vl_4b_instruct/checkpoints/Qwen3-VL-4B-Instruct
  dtype: bf16
dataset:
  name: vlm_coco2017_captions
  root: ${hydra:runtime.cwd}/datasets/vlm-quantize-calib
  size: medium
  captions_path: ${dataset.root}/coco2017_captions_${dataset.size}.txt
  size_to_max_samples:
    small: 16
    medium: 128
    large: 512
  max_calib_samples: null
  calib_seq_len: 512
quant_pair:
  name: wint8_aint8
  weight: int8
  activation: int8
  format_name: INT8_DEFAULT_CFG
  experimental: false
autoquant:
  method: gradient
  device: cuda
  batch_size: 8
  effective_bits: 8.0
  score_size: 128
  verbose: true
output_layout:
  name: tmp
  mode: tmp
  root_dir: ${hydra:runtime.cwd}/tmp/qwen3_lm_sensitivity
hardware:
  device_index: 0
experiment: qwen3_lm_sensitivity
runner:
  report_only: false
  output_dir: null
