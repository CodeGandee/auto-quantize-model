{
  "scheme": {
    "name": "wint8_aint4_autoquant_lm",
    "auto_quantize_bits": 8.74530701482171,
    "auto_quantize_method": "gradient",
    "auto_quantize_score_size": 128,
    "coverage_mode": "lm_only",
    "coverage_fraction": 1.0,
    "quant_formats": [
      "INT8_WEIGHT_INT4_ACT_CFG"
    ]
  },
  "model": {
    "id": "/workspace/code/auto-quantize-model/models/qwen3_vl_4b_instruct/checkpoints/Qwen3-VL-4B-Instruct"
  },
  "dataset": {
    "name": "vlm_coco2017_captions",
    "size": "medium",
    "root": "/workspace/code/auto-quantize-model/datasets/vlm-quantize-calib",
    "captions_path": "/workspace/code/auto-quantize-model/datasets/vlm-quantize-calib/coco2017_captions_medium.txt",
    "max_calib_samples": 128,
    "num_calib_samples": 128,
    "calib_seq_len": 512,
    "batch_size": 8,
    "num_calib_batches": 16
  },
  "autoquant_state": {
    "keys": [
      "candidate_stats",
      "best",
      "constraints"
    ],
    "constraints": {
      "effective_bits": 8.730416278760474
    },
    "score": 153.73293765593735,
    "is_satisfied": true
  },
  "layer_sensitivity": [
    {
      "layer": "model.language_model.layers.4.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 431.80470418930054,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 197.63856410980225,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.4.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 174.30088996887207,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 162.79803919792175,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 150.69762110710144,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 135.0785870552063,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 108.63280725479126,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 108.09535622596741,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 96.69475364685059,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 80.59577345848083,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 79.2539187669754,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 78.6903624534607,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 77.45566082000732,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 75.87772262096405,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 73.90239799022675,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 72.35116863250732,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 71.2798171043396,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 69.57226777076721,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 69.28681302070618,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 67.20444881916046,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 65.58283233642578,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 64.95539236068726,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 61.438467264175415,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 60.73965334892273,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 54.11756753921509,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 52.71533966064453,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 49.89324188232422,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 49.187254190444946,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 48.77483677864075,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 46.94444924592972,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 42.767887592315674,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 41.90126872062683,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 41.041236102581024,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 33.945483565330505,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 25.40046727657318,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 17.177536606788635,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 16.79449623823166,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 16.61736261844635,
      "size_cost": 6225920.0
    },
    {
      "layer": "lm_head",
      "num_bits": 4.0,
      "sensitivity": 13.16603809595108,
      "size_cost": 97239040.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 10.95668113231659,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 10.030444085597992,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 7.696232125163078,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 7.67955519258976,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 6.615756377577782,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 6.35958257317543,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 6.123912945389748,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 5.608564108610153,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 5.498393386602402,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 4.593398422002792,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 4.554907575249672,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 3.5360472947359085,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 3.450087293982506,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 2.6122663468122482,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 1.8856960907578468,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 1.6999724730849266,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 1.4260587394237518,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 1.0676658395677805,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.8469097949564457,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.8038279097527266,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.756373736076057,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.731241955421865,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.5673176497220993,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.3944713589735329,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.347271291539073,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.3125964868813753,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.28852732153609395,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.2784365154802799,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.24255704414099455,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.19040296785533428,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.17095925752073526,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.1683375472202897,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.13161931047216058,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0699018391314894,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.03334689552866621,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0171467516629491,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.016914871688641142,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.014464573847362772,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.011878297904331703,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.011230981024709763,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.010743952698248904,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.008949598173785489,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.008611360764916753,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.007547440582129639,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.00752272311001434,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.007350000094447751,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.007118158362573013,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.00682756432070164,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0067820276562997606,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0066833674973167945,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.006494968693004921,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0061543936008092714,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.006072604133805726,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.005826782322401414,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.005752053548349068,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.005308443494868698,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004998281179723563,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004821759572223527,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004808294899703469,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004546339016087586,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004166140552115394,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004134774650083273,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004106932632566895,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0038942139435675927,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.00388423018011963,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0037817769589310046,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0037210769351077033,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.003415288098040037,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0033635136314842384,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.003152035700622946,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0029645658087247284,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.002912744374043541,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.002859989006537944,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0028234727506060153,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0028195045379106887,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0023564276634715497,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.002305758564034477,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.002245042000140529,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.002217842578829732,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0020968105891370215,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0018624546864884906,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0015915627664071508,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0014499478438665392,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0012037419655825943,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.001185899665870238,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0011259522325417493,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0011168137352797203,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0010715710086515173,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0010336296545574442,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0010301509792043362,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.001001834109047195,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0009831127463257872,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0009375935769639909,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0009337877454527188,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0008284378454845864,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0008230924868257716,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0008211413623939734,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.000797628872533096,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0007820752834959421,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0007625150719832163,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.000742033138521947,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0006708920154778752,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.000637643679510802,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0006248230583878467,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0005778938575531356,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0005477269096445525,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.visual.patch_embed.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.0.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.0.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.1.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.2.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.3.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.4.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.5.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.6.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.7.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.8.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.9.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.10.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.11.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.12.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.13.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.14.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.15.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.16.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.17.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.18.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.19.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.20.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.21.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.22.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.23.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.merger.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.merger.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    }
  ]
}