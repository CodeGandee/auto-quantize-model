{
  "scheme": {
    "name": "wfp4_aint4_autoquant_lm",
    "auto_quantize_bits": 8.74530701482171,
    "auto_quantize_method": "gradient",
    "auto_quantize_score_size": 128,
    "coverage_mode": "lm_only",
    "coverage_fraction": 1.0,
    "quant_formats": [
      "NVFP4_WEIGHT_INT4_ACT_CFG"
    ]
  },
  "model": {
    "id": "/workspace/code/auto-quantize-model/models/qwen3_vl_4b_instruct/checkpoints/Qwen3-VL-4B-Instruct"
  },
  "dataset": {
    "name": "vlm_coco2017_captions",
    "size": "medium",
    "root": "/workspace/code/auto-quantize-model/datasets/vlm-quantize-calib",
    "captions_path": "/workspace/code/auto-quantize-model/datasets/vlm-quantize-calib/coco2017_captions_medium.txt",
    "max_calib_samples": 128,
    "num_calib_samples": 128,
    "calib_seq_len": 512,
    "batch_size": 8,
    "num_calib_batches": 16
  },
  "autoquant_state": {
    "keys": [
      "candidate_stats",
      "best",
      "constraints"
    ],
    "constraints": {
      "effective_bits": 8.730416278760474
    },
    "score": 154.72308784464713,
    "is_satisfied": true
  },
  "layer_sensitivity": [
    {
      "layer": "model.language_model.layers.4.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 421.9581413269043,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 203.56945705413818,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.4.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 174.3431854248047,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 164.24136066436768,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 149.28922629356384,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 134.8867838382721,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 111.25222826004028,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 108.32122254371643,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 96.6947193145752,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 80.81180942058563,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 79.46684348583221,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 78.64428353309631,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 77.33497595787048,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 76.0221643447876,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 73.06932020187378,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 72.85487163066864,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 71.77335393428802,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 70.41631710529327,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 69.28684782981873,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 67.32338201999664,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 65.58288979530334,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 64.95541524887085,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 61.43852877616882,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 60.745595932006836,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 54.12192106246948,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 52.71550750732422,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 49.89328718185425,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 49.21140122413635,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 48.774871826171875,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 46.86440771818161,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 42.81929659843445,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 41.915857791900635,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 41.57137590646744,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 33.94550573825836,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 25.38135051727295,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 17.28598228096962,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 16.794566750526428,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 16.69707453250885,
      "size_cost": 6225920.0
    },
    {
      "layer": "lm_head",
      "num_bits": 4.0,
      "sensitivity": 13.354351699352264,
      "size_cost": 97239040.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 10.923346757888794,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 9.984269589185715,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 7.6213908195495605,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 7.608597561717033,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 7.244857162237167,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 6.590785339474678,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 6.134753257036209,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 5.605026468634605,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 5.503698468208313,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 4.585358887910843,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 4.5494067668914795,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 3.530034489929676,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 3.4551650136709213,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 2.6083941757678986,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 1.9156202152371407,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 1.705601416528225,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 1.4268053472042084,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 1.0866150222718716,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.850042100995779,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.8067984338849783,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.7567045977339149,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.723879536613822,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.5671197175979614,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.3962768269702792,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.3480435498058796,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.31067442521452904,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.29013448767364025,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.27879789005964994,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.2467584777623415,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.19140692939981818,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.gate_proj",
      "num_bits": 4.0,
      "sensitivity": 0.18102473951876163,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.1713268831372261,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.13347904942929745,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.down_proj",
      "num_bits": 4.0,
      "sensitivity": 0.07030955259688199,
      "size_cost": 6225920.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.03350134803986293,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.01752198465692345,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.01700373608036898,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.014514391594275367,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.012006585922790691,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.011472124770079972,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.011001663173374254,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.009171846599201672,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.008954035507485969,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.007677600282477215,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.007578644173918292,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0075216831028228626,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.007347436796408147,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.007099108745023841,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0068431564468482975,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.006695962463709293,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0065779690485214815,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.006197210972459288,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.006163842193927849,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.006133478160336381,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.005705148356355494,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.005409664416220039,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.00522665436801617,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.005004419803299243,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004928521550027654,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004601174652634654,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004352477695647394,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004229131522151874,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.004160429560215562,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.003988369173384854,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0039232649869518355,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.003922616078853025,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.003906499285221798,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0034618844892975176,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.003427813935559243,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0031752489740028977,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.003066593102630577,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0030535631558450405,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0028879026795038953,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0028359371499391273,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0028252788179088384,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0023856892294134013,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.002363525934924837,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0023320029795286246,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0022703682334395126,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0021440071432152763,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0019119292192044668,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0016454899523523636,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.q_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0015587484331263113,
      "size_cost": 3932160.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0012342153713689186,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0012033484963467345,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0011506792034197133,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.001148286468378501,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0011127837315143552,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0010632800112944096,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0010548050559009425,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0010175269817409571,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.000997687951894477,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0009698956964712124,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0009517234284430742,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0008497523849655408,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0008384869070141576,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0008380611070606392,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.000826326559035806,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0007941066833154764,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0007800229213899001,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0007539935068052728,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.000692252091539558,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0006477557108155452,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0006458643620135263,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0005916976097068982,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.o_proj",
      "num_bits": 4.0,
      "sensitivity": 0.0005500215029314859,
      "size_cost": 2621440.0
    },
    {
      "layer": "model.visual.patch_embed.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.0.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.0.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.1.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.2.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.3.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.4.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.5.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.6.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.7.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.8.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.9.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.10.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.11.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.12.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.13.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.14.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.15.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.16.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.17.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.18.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.19.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.20.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.21.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.22.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.23.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.merger.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.merger.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    }
  ]
}