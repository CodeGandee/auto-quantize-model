{
  "scheme": {
    "name": "wint8_afp16_autoquant_lm",
    "auto_quantize_bits": 8.74530701482171,
    "auto_quantize_method": "gradient",
    "auto_quantize_score_size": 128,
    "coverage_mode": "lm_only",
    "coverage_fraction": 1.0,
    "quant_formats": [
      "INT8_WEIGHT_ONLY_CFG"
    ]
  },
  "model": {
    "id": "/workspace/code/auto-quantize-model/models/qwen3_vl_4b_instruct/checkpoints/Qwen3-VL-4B-Instruct"
  },
  "autoquant_state": {
    "keys": [
      "candidate_stats",
      "best",
      "constraints"
    ],
    "constraints": {
      "effective_bits": 8.744307014821711
    },
    "score": 0.4011312231468447,
    "is_satisfied": true
  },
  "layer_sensitivity": [
    {
      "layer": "model.language_model.layers.0.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.037937596323899925,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.4.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.031166533939540386,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.026490792457479984,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.023755057773087174,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.4.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.01893386640585959,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.016499699151609093,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.015791656071087345,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.012833598622819409,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.012579025002196431,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.010971763753332198,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.6.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.009535610064631328,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.5.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.009493206511251628,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.008832935855025426,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.3.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.008333969512023032,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.008216800677473657,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.008193681118427776,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.008111740942695178,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007893837813753635,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.0.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007787396680214442,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007338352937949821,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007257484816364013,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.14.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007249838818097487,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.13.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007239828642923385,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007193568759248592,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.2.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.006733510497724637,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.9.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.006019166292389855,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.10.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.005869297223398462,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.15.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.005719833017792553,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.12.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.005500928935362026,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.7.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.005445259972475469,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0051225055431132205,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.8.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0050514324102550745,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.11.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00395695427141618,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0037023463009973057,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.16.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0036147882201476023,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0031030459940666333,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.1.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0029512799956137314,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.17.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0021642100255121477,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.18.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.001972149926587008,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0019587506394600496,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.19.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0014281558032962494,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0012157676574133802,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0011133408752357354,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0010394063137937337,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.22.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0009558391284372192,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.20.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.000843249807076063,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.21.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0007126633536245208,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0006878221483930247,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0005336612548489938,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.23.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0004834098908759188,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0004262419734004652,
      "size_cost": 24903680.0
    },
    {
      "layer": "lm_head",
      "num_bits": 8.0,
      "sensitivity": 0.00041104938281932846,
      "size_cost": 194478080.0
    },
    {
      "layer": "model.language_model.layers.24.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0003520734808262205,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0002659369583852822,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.25.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00025941001422324916,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0002505322504475771,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00020516672248049872,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.26.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001896232070066617,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.27.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00014040978476259625,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00011937705676245969,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.35.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00011332546546327649,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 9.156423857348273e-05,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 8.179662313523295e-05,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.28.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 8.0701427123131e-05,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.32.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 7.332175766805449e-05,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.34.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 7.017231951067515e-05,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 6.740902836099849e-05,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 5.599144844836701e-05,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.29.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 5.268164181870816e-05,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 4.593029393618053e-05,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.33.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 4.5514498594911856e-05,
      "size_cost": 24903680.0
    },
    {
      "layer": "model.language_model.layers.30.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 4.2304319322283845e-05,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.31.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 3.268686555202294e-05,
      "size_cost": 12451840.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.0187099048764026e-05,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.6433479020133746e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4.533065233403022e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4.1148259506407214e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 4.0358044675059546e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.942674996260109e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.93754282157488e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.7831358756790223e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.7610610554850155e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.6240284924105026e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.5753335243526863e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.4364847376622265e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.320597775413603e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.256827955766539e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.0670415087641345e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.7670297484405637e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.5911016816593246e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.509730977706681e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.503169566736574e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.6.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.4195172656504838e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.3960728663396935e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.227235433416297e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.0019406417048913e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.9528263006662883e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.7880033889028368e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.0.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.6866053265118808e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.6726370066777463e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.5664684545058094e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.5531492110198997e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4866600599461322e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4705272031179106e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4635434535392733e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3774230591678815e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.312728180380418e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2859634557216282e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 1.266702117419527e-06,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.23.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.0242353631895185e-06,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.35.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 9.100951849916328e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.142803045174674e-07,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.22.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 7.96277550563218e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.24.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.79421514604428e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.8.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.77672995053058e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.414685052025249e-07,
      "size_cost": 7864320.0
    },
    {
      "layer": "model.language_model.layers.12.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.286414482303826e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.15.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.958796887028939e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.14.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.953416604143058e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.1.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.867011676485845e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.10.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.606794157841932e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.16.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.302784380489811e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.19.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.017078414937259e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.5.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.982958508037427e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.7.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.843664065390385e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.21.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.7601946029374176e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.34.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.650930698346656e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.9.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.619042464071299e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.18.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.3081091583019315e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.20.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.8995555939891346e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.4.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.87546479352352e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.17.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.7434786470669223e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.11.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.7313234990676847e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.28.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.4564496687039536e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.13.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.1584161597209004e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.26.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.079367143499212e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.30.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.9222876740675474e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.3.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.818419506667169e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.27.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.708334356782416e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.25.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.533909313484628e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.2.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.205749449757377e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.31.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.973882426398177e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.32.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.9689934926958585e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.29.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.7460853474204896e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.language_model.layers.33.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2498844492725425e-07,
      "size_cost": 5242880.0
    },
    {
      "layer": "model.visual.patch_embed.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1572864.0
    },
    {
      "layer": "model.visual.blocks.0.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.0.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.0.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.1.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.1.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.2.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.2.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.3.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.3.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.4.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.4.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.5.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.5.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.6.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.6.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.7.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.7.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.8.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.8.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.9.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.9.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.10.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.10.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.11.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.11.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.12.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.12.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.13.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.13.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.14.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.14.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.15.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.15.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.16.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.16.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.17.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.17.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.18.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.18.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.19.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.19.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.20.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.20.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.21.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.21.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.22.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.22.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.attn.qkv",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 3145728.0
    },
    {
      "layer": "model.visual.blocks.23.attn.proj",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 1048576.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.blocks.23.mlp.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 4194304.0
    },
    {
      "layer": "model.visual.merger.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.merger.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.0.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.1.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc1",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 16777216.0
    },
    {
      "layer": "model.visual.deepstack_merger_list.2.linear_fc2",
      "num_bits": 16.0,
      "sensitivity": 0.0,
      "size_cost": 10485760.0
    }
  ]
}