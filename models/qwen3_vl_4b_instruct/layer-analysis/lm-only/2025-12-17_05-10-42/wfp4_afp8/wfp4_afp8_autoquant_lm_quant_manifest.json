{
  "scheme": {
    "name": "wfp4_afp8_autoquant_lm",
    "auto_quantize_bits": 8.74530701482171,
    "auto_quantize_method": "gradient",
    "auto_quantize_score_size": 128,
    "coverage_mode": "lm_only",
    "coverage_fraction": 1.0,
    "quant_formats": [
      "W4A8_NVFP4_FP8_CFG"
    ]
  },
  "model": {
    "id": "/workspace/code/auto-quantize-model/models/qwen3_vl_4b_instruct/checkpoints/Qwen3-VL-4B-Instruct"
  },
  "num_quantized_layers": 357,
  "layers": {
    "model.visual.blocks.0.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.0.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.0.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.0.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.1.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.1.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.1.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.1.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.2.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.2.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.2.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.2.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.3.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.3.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.3.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.3.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.4.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.4.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.4.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.4.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.5.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.5.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.5.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.5.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.6.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.6.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.6.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.6.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.7.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.7.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.7.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.7.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.8.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.8.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.8.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.8.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.9.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.9.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.9.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.9.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.10.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.10.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.10.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.10.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.11.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.11.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.11.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.11.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.12.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.12.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.12.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.12.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.13.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.13.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.13.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.13.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.14.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.14.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.14.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.14.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.15.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.15.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.15.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.15.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.16.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.16.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.16.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.16.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.17.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.17.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.17.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.17.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.18.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.18.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.18.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.18.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.19.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.19.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.19.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.19.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.20.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.20.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.20.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.20.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.21.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.21.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.21.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.21.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.22.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.22.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.22.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.22.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.23.attn.qkv": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.23.attn.proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.23.mlp.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.blocks.23.mlp.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.merger.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.merger.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.deepstack_merger_list.0.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.deepstack_merger_list.0.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.deepstack_merger_list.1.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.deepstack_merger_list.1.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.deepstack_merger_list.2.linear_fc1": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.visual.deepstack_merger_list.2.linear_fc2": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.0.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.0.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.0.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.0.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.0.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.0.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.0.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.1.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.1.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.1.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.1.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.1.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.1.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.1.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.2.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.2.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.2.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.2.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.2.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.2.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.2.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.3.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.3.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.3.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.3.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.3.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.3.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.3.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.4.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.4.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.4.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.4.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.4.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.4.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.4.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.5.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.5.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.5.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.5.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.5.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.5.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.5.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.6.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.6.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.6.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.6.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.6.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.6.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.6.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.7.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.7.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.7.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.7.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.7.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.7.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.7.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.8.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.8.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.8.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.8.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.8.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.8.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.8.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.9.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.9.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.9.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.9.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.9.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.9.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.9.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.10.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.10.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.10.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.10.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.10.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.10.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.10.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.11.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.11.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.11.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.11.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.11.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.11.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.11.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.12.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.12.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.12.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.12.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.12.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.12.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.12.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.13.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.13.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.13.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.13.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.13.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.13.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.13.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.14.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.14.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.14.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.14.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.14.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.14.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.14.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.15.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.15.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.15.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.15.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.15.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.15.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.15.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.16.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.16.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.16.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.16.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.16.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.16.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.16.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.17.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.17.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.17.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.17.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.17.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.17.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.17.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.18.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.18.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.18.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.18.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.18.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.18.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.18.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.19.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.19.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.19.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.19.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.19.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.19.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.19.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.20.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.20.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.20.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.20.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.20.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.20.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.20.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.21.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.21.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.21.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.21.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.21.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.21.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.21.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.22.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.22.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.22.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.22.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.22.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.22.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.22.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.23.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.23.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.23.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.23.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.23.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.23.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.23.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.24.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.24.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.24.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.24.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.24.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.24.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.24.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.25.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.25.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.25.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.25.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.25.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.25.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.25.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.26.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.26.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.26.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.26.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.26.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.26.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.26.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.27.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.27.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.27.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.27.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.27.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.27.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.27.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.28.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.28.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.28.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.28.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.28.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.28.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.28.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.29.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.29.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.29.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.29.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.29.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.29.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.29.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.30.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.30.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.30.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.30.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.30.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.30.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.30.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.31.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.31.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.31.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.31.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.31.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.31.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.31.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.32.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.32.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.32.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.32.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.32.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.32.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.32.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.33.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.33.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.33.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.33.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.33.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.33.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.33.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.34.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.34.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.34.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.34.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.34.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.34.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.34.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.35.self_attn.q_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.35.self_attn.k_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.35.self_attn.v_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.35.self_attn.o_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.35.mlp.gate_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.35.mlp.up_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "model.language_model.layers.35.mlp.down_proj": {
      "quantized": true,
      "module_type": "QuantLinear"
    },
    "lm_head": {
      "quantized": true,
      "module_type": "QuantLinear"
    }
  },
  "autoquant_state": {
    "keys": [
      "candidate_stats",
      "best",
      "constraints"
    ],
    "constraints": {
      "effective_bits": 8.730416278760474
    },
    "score": 1.8922478849051885,
    "is_satisfied": true
  },
  "layer_sensitivity": {
    "model.visual.patch_embed.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1572864.0
      ],
      "importance": 0.0,
      "rank": 1
    },
    "model.visual.blocks.0.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 2
    },
    "model.visual.blocks.0.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 3
    },
    "model.visual.blocks.0.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 4
    },
    "model.visual.blocks.0.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 5
    },
    "model.visual.blocks.1.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 6
    },
    "model.visual.blocks.1.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 7
    },
    "model.visual.blocks.1.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 8
    },
    "model.visual.blocks.1.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 9
    },
    "model.visual.blocks.2.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 10
    },
    "model.visual.blocks.2.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 11
    },
    "model.visual.blocks.2.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 12
    },
    "model.visual.blocks.2.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 13
    },
    "model.visual.blocks.3.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 14
    },
    "model.visual.blocks.3.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 15
    },
    "model.visual.blocks.3.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 16
    },
    "model.visual.blocks.3.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 17
    },
    "model.visual.blocks.4.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 18
    },
    "model.visual.blocks.4.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 19
    },
    "model.visual.blocks.4.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 20
    },
    "model.visual.blocks.4.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 21
    },
    "model.visual.blocks.5.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 22
    },
    "model.visual.blocks.5.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 23
    },
    "model.visual.blocks.5.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 24
    },
    "model.visual.blocks.5.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 25
    },
    "model.visual.blocks.6.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 26
    },
    "model.visual.blocks.6.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 27
    },
    "model.visual.blocks.6.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 28
    },
    "model.visual.blocks.6.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 29
    },
    "model.visual.blocks.7.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 30
    },
    "model.visual.blocks.7.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 31
    },
    "model.visual.blocks.7.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 32
    },
    "model.visual.blocks.7.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 33
    },
    "model.visual.blocks.8.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 34
    },
    "model.visual.blocks.8.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 35
    },
    "model.visual.blocks.8.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 36
    },
    "model.visual.blocks.8.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 37
    },
    "model.visual.blocks.9.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 38
    },
    "model.visual.blocks.9.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 39
    },
    "model.visual.blocks.9.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 40
    },
    "model.visual.blocks.9.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 41
    },
    "model.visual.blocks.10.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 42
    },
    "model.visual.blocks.10.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 43
    },
    "model.visual.blocks.10.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 44
    },
    "model.visual.blocks.10.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 45
    },
    "model.visual.blocks.11.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 46
    },
    "model.visual.blocks.11.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 47
    },
    "model.visual.blocks.11.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 48
    },
    "model.visual.blocks.11.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 49
    },
    "model.visual.blocks.12.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 50
    },
    "model.visual.blocks.12.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 51
    },
    "model.visual.blocks.12.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 52
    },
    "model.visual.blocks.12.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 53
    },
    "model.visual.blocks.13.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 54
    },
    "model.visual.blocks.13.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 55
    },
    "model.visual.blocks.13.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 56
    },
    "model.visual.blocks.13.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 57
    },
    "model.visual.blocks.14.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 58
    },
    "model.visual.blocks.14.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 59
    },
    "model.visual.blocks.14.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 60
    },
    "model.visual.blocks.14.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 61
    },
    "model.visual.blocks.15.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 62
    },
    "model.visual.blocks.15.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 63
    },
    "model.visual.blocks.15.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 64
    },
    "model.visual.blocks.15.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 65
    },
    "model.visual.blocks.16.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 66
    },
    "model.visual.blocks.16.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 67
    },
    "model.visual.blocks.16.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 68
    },
    "model.visual.blocks.16.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 69
    },
    "model.visual.blocks.17.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 70
    },
    "model.visual.blocks.17.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 71
    },
    "model.visual.blocks.17.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 72
    },
    "model.visual.blocks.17.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 73
    },
    "model.visual.blocks.18.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 74
    },
    "model.visual.blocks.18.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 75
    },
    "model.visual.blocks.18.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 76
    },
    "model.visual.blocks.18.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 77
    },
    "model.visual.blocks.19.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 78
    },
    "model.visual.blocks.19.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 79
    },
    "model.visual.blocks.19.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 80
    },
    "model.visual.blocks.19.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 81
    },
    "model.visual.blocks.20.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 82
    },
    "model.visual.blocks.20.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 83
    },
    "model.visual.blocks.20.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 84
    },
    "model.visual.blocks.20.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 85
    },
    "model.visual.blocks.21.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 86
    },
    "model.visual.blocks.21.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 87
    },
    "model.visual.blocks.21.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 88
    },
    "model.visual.blocks.21.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 89
    },
    "model.visual.blocks.22.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 90
    },
    "model.visual.blocks.22.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 91
    },
    "model.visual.blocks.22.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 92
    },
    "model.visual.blocks.22.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 93
    },
    "model.visual.blocks.23.attn.qkv.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        3145728.0
      ],
      "importance": 0.0,
      "rank": 94
    },
    "model.visual.blocks.23.attn.proj.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        1048576.0
      ],
      "importance": 0.0,
      "rank": 95
    },
    "model.visual.blocks.23.mlp.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 96
    },
    "model.visual.blocks.23.mlp.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        4194304.0
      ],
      "importance": 0.0,
      "rank": 97
    },
    "model.visual.merger.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        16777216.0
      ],
      "importance": 0.0,
      "rank": 98
    },
    "model.visual.merger.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        10485760.0
      ],
      "importance": 0.0,
      "rank": 99
    },
    "model.visual.deepstack_merger_list.0.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        16777216.0
      ],
      "importance": 0.0,
      "rank": 100
    },
    "model.visual.deepstack_merger_list.0.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        10485760.0
      ],
      "importance": 0.0,
      "rank": 101
    },
    "model.visual.deepstack_merger_list.1.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        16777216.0
      ],
      "importance": 0.0,
      "rank": 102
    },
    "model.visual.deepstack_merger_list.1.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        10485760.0
      ],
      "importance": 0.0,
      "rank": 103
    },
    "model.visual.deepstack_merger_list.2.linear_fc1.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        16777216.0
      ],
      "importance": 0.0,
      "rank": 104
    },
    "model.visual.deepstack_merger_list.2.linear_fc2.quant_recipe": {
      "formats": [
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0
      ],
      "costs": [
        10485760.0
      ],
      "importance": 0.0,
      "rank": 105
    },
    "model.language_model.layers.0.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00036924227026702283,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00036924227026702283,
      "rank": 177
    },
    "model.language_model.layers.0.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00012433590063665179,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 0.00012433590063665179,
      "rank": 161
    },
    "model.language_model.layers.0.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.7682000957429409,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.7682000957429409,
      "rank": 241
    },
    "model.language_model.layers.0.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.766656205058098,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 2.766656205058098,
      "rank": 250
    },
    "model.language_model.layers.1.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        5.51954801011334e-05,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 5.51954801011334e-05,
      "rank": 138
    },
    "model.language_model.layers.1.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        4.119380230349634e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 4.119380230349634e-05,
      "rank": 129
    },
    "model.language_model.layers.1.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.5066836448386312,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.5066836448386312,
      "rank": 230
    },
    "model.language_model.layers.1.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.19570928253233433,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.19570928253233433,
      "rank": 214
    },
    "model.language_model.layers.2.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        4.800308013841459e-05,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 4.800308013841459e-05,
      "rank": 136
    },
    "model.language_model.layers.2.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        1.7749386870491435e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 1.7749386870491435e-05,
      "rank": 110
    },
    "model.language_model.layers.2.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        1.3884448632597923,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 1.3884448632597923,
      "rank": 247
    },
    "model.language_model.layers.2.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.3025950836017728,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.3025950836017728,
      "rank": 218
    },
    "model.language_model.layers.3.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        7.34868021083912e-05,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 7.34868021083912e-05,
      "rank": 142
    },
    "model.language_model.layers.3.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.1785841738619638e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.1785841738619638e-05,
      "rank": 112
    },
    "model.language_model.layers.3.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        1.8539249747991562,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 1.8539249747991562,
      "rank": 248
    },
    "model.language_model.layers.3.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.4475914239883423,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.4475914239883423,
      "rank": 227
    },
    "model.language_model.layers.4.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        8.918459377582622e-05,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 8.918459377582622e-05,
      "rank": 148
    },
    "model.language_model.layers.4.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        3.3044994665942795e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 3.3044994665942795e-05,
      "rank": 124
    },
    "model.language_model.layers.4.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.4106449112296104,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 2.4106449112296104,
      "rank": 249
    },
    "model.language_model.layers.4.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.9745144248008728,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.9745144248008728,
      "rank": 243
    },
    "model.language_model.layers.5.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00011237741830427694,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00011237741830427694,
      "rank": 155
    },
    "model.language_model.layers.5.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        4.175558478891617e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 4.175558478891617e-05,
      "rank": 130
    },
    "model.language_model.layers.5.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        1.356670554727316,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 1.356670554727316,
      "rank": 246
    },
    "model.language_model.layers.5.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.7142941392958164,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.7142941392958164,
      "rank": 238
    },
    "model.language_model.layers.6.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00014429849704811204,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00014429849704811204,
      "rank": 164
    },
    "model.language_model.layers.6.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00013715316208617878,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 0.00013715316208617878,
      "rank": 163
    },
    "model.language_model.layers.6.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        1.1565511859953403,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 1.1565511859953403,
      "rank": 245
    },
    "model.language_model.layers.6.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.6001670248806477,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.6001670248806477,
      "rank": 233
    },
    "model.language_model.layers.7.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0001706148292441867,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.0001706148292441867,
      "rank": 168
    },
    "model.language_model.layers.7.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        4.251587677117641e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 4.251587677117641e-05,
      "rank": 132
    },
    "model.language_model.layers.7.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        1.0310780983418226,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 1.0310780983418226,
      "rank": 244
    },
    "model.language_model.layers.7.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.3630667105317116,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.3630667105317116,
      "rank": 222
    },
    "model.language_model.layers.8.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00016957324066879664,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00016957324066879664,
      "rank": 167
    },
    "model.language_model.layers.8.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        6.435199929910596e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 6.435199929910596e-05,
      "rank": 141
    },
    "model.language_model.layers.8.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.6919713038951159,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.6919713038951159,
      "rank": 237
    },
    "model.language_model.layers.8.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.34285296499729156,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.34285296499729156,
      "rank": 221
    },
    "model.language_model.layers.9.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00020340952312380978,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00020340952312380978,
      "rank": 174
    },
    "model.language_model.layers.9.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        4.078883262081945e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 4.078883262081945e-05,
      "rank": 128
    },
    "model.language_model.layers.9.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.6916103232651949,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.6916103232651949,
      "rank": 236
    },
    "model.language_model.layers.9.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.43876457773149014,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.43876457773149014,
      "rank": 226
    },
    "model.language_model.layers.10.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0001929598255401288,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.0001929598255401288,
      "rank": 172
    },
    "model.language_model.layers.10.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        4.47301805479583e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 4.47301805479583e-05,
      "rank": 134
    },
    "model.language_model.layers.10.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.7405918603762984,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.7405918603762984,
      "rank": 240
    },
    "model.language_model.layers.10.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.43569557555019855,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.43569557555019855,
      "rank": 225
    },
    "model.language_model.layers.11.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00011294577302578546,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00011294577302578546,
      "rank": 156
    },
    "model.language_model.layers.11.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        3.452380678936606e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 3.452380678936606e-05,
      "rank": 125
    },
    "model.language_model.layers.11.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.5988997286185622,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.5988997286185622,
      "rank": 232
    },
    "model.language_model.layers.11.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.32309514470398426,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.32309514470398426,
      "rank": 219
    },
    "model.language_model.layers.12.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        7.635171829178944e-05,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 7.635171829178944e-05,
      "rank": 143
    },
    "model.language_model.layers.12.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        4.1906343767550425e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 4.1906343767550425e-05,
      "rank": 131
    },
    "model.language_model.layers.12.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.7206101631745696,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.7206101631745696,
      "rank": 239
    },
    "model.language_model.layers.12.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.4287195485085249,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.4287195485085249,
      "rank": 224
    },
    "model.language_model.layers.13.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        9.163172632042915e-05,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 9.163172632042915e-05,
      "rank": 149
    },
    "model.language_model.layers.13.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.7204659659219033e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.7204659659219033e-05,
      "rank": 118
    },
    "model.language_model.layers.13.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.6306649632751942,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.6306649632751942,
      "rank": 234
    },
    "model.language_model.layers.13.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.5381579101085663,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.5381579101085663,
      "rank": 231
    },
    "model.language_model.layers.14.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0001832663248251265,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.0001832663248251265,
      "rank": 170
    },
    "model.language_model.layers.14.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        4.451778067959822e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 4.451778067959822e-05,
      "rank": 133
    },
    "model.language_model.layers.14.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.8000804036855698,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.8000804036855698,
      "rank": 242
    },
    "model.language_model.layers.14.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.4493721257895231,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.4493721257895231,
      "rank": 228
    },
    "model.language_model.layers.15.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00011733550695680606,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00011733550695680606,
      "rank": 158
    },
    "model.language_model.layers.15.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        4.9878826075655525e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 4.9878826075655525e-05,
      "rank": 137
    },
    "model.language_model.layers.15.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.6791880391538143,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.6791880391538143,
      "rank": 235
    },
    "model.language_model.layers.15.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.38646308705210686,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.38646308705210686,
      "rank": 223
    },
    "model.language_model.layers.16.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        9.710752237879205e-05,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 9.710752237879205e-05,
      "rank": 150
    },
    "model.language_model.layers.16.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        3.565310476005834e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 3.565310476005834e-05,
      "rank": 126
    },
    "model.language_model.layers.16.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.5045877434313297,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.5045877434313297,
      "rank": 229
    },
    "model.language_model.layers.16.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.24369711335748434,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.24369711335748434,
      "rank": 216
    },
    "model.language_model.layers.17.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        8.738651706607925e-05,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 8.738651706607925e-05,
      "rank": 146
    },
    "model.language_model.layers.17.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.6085949457410607e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.6085949457410607e-05,
      "rank": 117
    },
    "model.language_model.layers.17.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.329732745885849,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.329732745885849,
      "rank": 220
    },
    "model.language_model.layers.17.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.15107910428196192,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.15107910428196192,
      "rank": 212
    },
    "model.language_model.layers.18.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00010349754415983625,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00010349754415983625,
      "rank": 151
    },
    "model.language_model.layers.18.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.7501244971972483e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.7501244971972483e-05,
      "rank": 120
    },
    "model.language_model.layers.18.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.2281972379423678,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.2281972379423678,
      "rank": 215
    },
    "model.language_model.layers.18.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.12571820430457592,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.12571820430457592,
      "rank": 211
    },
    "model.language_model.layers.19.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00010665617571703478,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00010665617571703478,
      "rank": 152
    },
    "model.language_model.layers.19.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.9029236998212582e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.9029236998212582e-05,
      "rank": 122
    },
    "model.language_model.layers.19.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.16311313305050135,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.16311313305050135,
      "rank": 213
    },
    "model.language_model.layers.19.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.08457813691347837,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.08457813691347837,
      "rank": 208
    },
    "model.language_model.layers.20.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        7.933083998068469e-05,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 7.933083998068469e-05,
      "rank": 144
    },
    "model.language_model.layers.20.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.5302112703684543e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.5302112703684543e-05,
      "rank": 116
    },
    "model.language_model.layers.20.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.11330653913319111,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.11330653913319111,
      "rank": 210
    },
    "model.language_model.layers.20.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.053387322230264544,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.053387322230264544,
      "rank": 205
    },
    "model.language_model.layers.21.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00019285434098037513,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00019285434098037513,
      "rank": 171
    },
    "model.language_model.layers.21.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.866190391159762e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.866190391159762e-05,
      "rank": 121
    },
    "model.language_model.layers.21.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.09051002841442823,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.09051002841442823,
      "rank": 209
    },
    "model.language_model.layers.21.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.04598381253890693,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.04598381253890693,
      "rank": 202
    },
    "model.language_model.layers.22.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00019664229284899193,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00019664229284899193,
      "rank": 173
    },
    "model.language_model.layers.22.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        4.717753290606197e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 4.717753290606197e-05,
      "rank": 135
    },
    "model.language_model.layers.22.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.07372195972129703,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.07372195972129703,
      "rank": 207
    },
    "model.language_model.layers.22.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0487591119017452,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.0487591119017452,
      "rank": 203
    },
    "model.language_model.layers.23.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00020492899170676537,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00020492899170676537,
      "rank": 175
    },
    "model.language_model.layers.23.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        5.781165600637905e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 5.781165600637905e-05,
      "rank": 140
    },
    "model.language_model.layers.23.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.06908084871247411,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.06908084871247411,
      "rank": 206
    },
    "model.language_model.layers.23.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.03049649891909212,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.03049649891909212,
      "rank": 199
    },
    "model.language_model.layers.24.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00016431726214705122,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00016431726214705122,
      "rank": 166
    },
    "model.language_model.layers.24.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        3.8404190718210884e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 3.8404190718210884e-05,
      "rank": 127
    },
    "model.language_model.layers.24.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0529621479799971,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.0529621479799971,
      "rank": 204
    },
    "model.language_model.layers.24.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.023389000445604324,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.023389000445604324,
      "rank": 197
    },
    "model.language_model.layers.25.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0001259296655007347,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.0001259296655007347,
      "rank": 162
    },
    "model.language_model.layers.25.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.1352330406898545e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.1352330406898545e-05,
      "rank": 111
    },
    "model.language_model.layers.25.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.04099291970487684,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.04099291970487684,
      "rank": 201
    },
    "model.language_model.layers.25.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.019249645760282874,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.019249645760282874,
      "rank": 195
    },
    "model.language_model.layers.26.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00015519691612553288,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00015519691612553288,
      "rank": 165
    },
    "model.language_model.layers.26.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.4117341126839165e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.4117341126839165e-05,
      "rank": 115
    },
    "model.language_model.layers.26.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0301383092883043,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.0301383092883043,
      "rank": 198
    },
    "model.language_model.layers.26.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.014128082490060478,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.014128082490060478,
      "rank": 194
    },
    "model.language_model.layers.27.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00010698880117843146,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00010698880117843146,
      "rank": 153
    },
    "model.language_model.layers.27.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.2495826215163106e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.2495826215163106e-05,
      "rank": 113
    },
    "model.language_model.layers.27.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.020910948544042185,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.020910948544042185,
      "rank": 196
    },
    "model.language_model.layers.27.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.009238495375029743,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.009238495375029743,
      "rank": 192
    },
    "model.language_model.layers.28.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00012182702357677044,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00012182702357677044,
      "rank": 159
    },
    "model.language_model.layers.28.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.7344533691575634e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.7344533691575634e-05,
      "rank": 119
    },
    "model.language_model.layers.28.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.01243322718073614,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.01243322718073614,
      "rank": 193
    },
    "model.language_model.layers.28.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.005517322395462543,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.005517322395462543,
      "rank": 189
    },
    "model.language_model.layers.29.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        8.816931165256392e-05,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 8.816931165256392e-05,
      "rank": 147
    },
    "model.language_model.layers.29.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        1.6306741827065707e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 1.6306741827065707e-05,
      "rank": 107
    },
    "model.language_model.layers.29.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.008136801785440184,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.008136801785440184,
      "rank": 191
    },
    "model.language_model.layers.29.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.003497755475109443,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.003497755475109443,
      "rank": 185
    },
    "model.language_model.layers.30.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0001229115654268753,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.0001229115654268753,
      "rank": 160
    },
    "model.language_model.layers.30.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        2.2526705492964538e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 2.2526705492964538e-05,
      "rank": 114
    },
    "model.language_model.layers.30.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.005343278528016526,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.005343278528016526,
      "rank": 188
    },
    "model.language_model.layers.30.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.002775914268568158,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.002775914268568158,
      "rank": 183
    },
    "model.language_model.layers.31.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00011006023044046742,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00011006023044046742,
      "rank": 154
    },
    "model.language_model.layers.31.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        1.7082093734188675e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 1.7082093734188675e-05,
      "rank": 109
    },
    "model.language_model.layers.31.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.004516059620073065,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.004516059620073065,
      "rank": 187
    },
    "model.language_model.layers.31.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0021604772919090465,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.0021604772919090465,
      "rank": 181
    },
    "model.language_model.layers.32.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00011373171685136185,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00011373171685136185,
      "rank": 157
    },
    "model.language_model.layers.32.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        1.6582119940267148e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 1.6582119940267148e-05,
      "rank": 108
    },
    "model.language_model.layers.32.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0037106874951859936,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.0037106874951859936,
      "rank": 186
    },
    "model.language_model.layers.32.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0017004816472763196,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.0017004816472763196,
      "rank": 180
    },
    "model.language_model.layers.33.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        8.171949741608842e-05,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 8.171949741608842e-05,
      "rank": 145
    },
    "model.language_model.layers.33.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        1.0134668400496594e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 1.0134668400496594e-05,
      "rank": 106
    },
    "model.language_model.layers.33.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0024301537559949793,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.0024301537559949793,
      "rank": 182
    },
    "model.language_model.layers.33.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0010487482977623586,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.0010487482977623586,
      "rank": 178
    },
    "model.language_model.layers.34.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.00017387752018294123,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.00017387752018294123,
      "rank": 169
    },
    "model.language_model.layers.34.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        3.097374826666055e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 3.097374826666055e-05,
      "rank": 123
    },
    "model.language_model.layers.34.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.008049389150983188,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.008049389150983188,
      "rank": 190
    },
    "model.language_model.layers.34.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0013042406426393427,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.0013042406426393427,
      "rank": 179
    },
    "model.language_model.layers.35.self_attn.q_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.0002510994436306646,
        0.0
      ],
      "costs": [
        3932160.0,
        15728640.0
      ],
      "importance": 0.0002510994436306646,
      "rank": 176
    },
    "model.language_model.layers.35.self_attn.o_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        5.536005505746289e-05,
        0.0
      ],
      "costs": [
        2621440.0,
        10485760.0
      ],
      "importance": 5.536005505746289e-05,
      "rank": 139
    },
    "model.language_model.layers.35.mlp.gate_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.3003386161290109,
        0.0
      ],
      "costs": [
        12451840.0,
        49807360.0
      ],
      "importance": 0.3003386161290109,
      "rank": 217
    },
    "model.language_model.layers.35.mlp.down_proj.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.002819268047460355,
        0.0
      ],
      "costs": [
        6225920.0,
        24903680.0
      ],
      "importance": 0.002819268047460355,
      "rank": 184
    },
    "lm_head.quant_recipe": {
      "formats": [
        "W4A8_NVFP4_FP8_CFG(effective-bits: 4.0)",
        "NONE(effective-bits: 16.0)"
      ],
      "scores": [
        0.031611767946742475,
        0.0
      ],
      "costs": [
        97239040.0,
        388956160.0
      ],
      "importance": 0.031611767946742475,
      "rank": 200
    }
  },
  "sensitivity_ranking": [
    {
      "name": "model.visual.patch_embed.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.0.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.0.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.0.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.0.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.1.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.1.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.1.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.1.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.2.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.2.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.2.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.2.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.3.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.3.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.3.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.3.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.4.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.4.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.4.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.4.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.5.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.5.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.5.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.5.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.6.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.6.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.6.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.6.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.7.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.7.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.7.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.7.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.8.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.8.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.8.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.8.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.9.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.9.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.9.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.9.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.10.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.10.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.10.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.10.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.11.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.11.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.11.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.11.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.12.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.12.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.12.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.12.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.13.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.13.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.13.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.13.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.14.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.14.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.14.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.14.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.15.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.15.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.15.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.15.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.16.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.16.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.16.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.16.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.17.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.17.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.17.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.17.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.18.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.18.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.18.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.18.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.19.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.19.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.19.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.19.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.20.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.20.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.20.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.20.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.21.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.21.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.21.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.21.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.22.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.22.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.22.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.22.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.23.attn.qkv.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.23.attn.proj.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.23.mlp.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.blocks.23.mlp.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.merger.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.merger.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.deepstack_merger_list.0.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.deepstack_merger_list.0.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.deepstack_merger_list.1.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.deepstack_merger_list.1.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.deepstack_merger_list.2.linear_fc1.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.visual.deepstack_merger_list.2.linear_fc2.quant_recipe",
      "importance": 0.0
    },
    {
      "name": "model.language_model.layers.33.self_attn.o_proj.quant_recipe",
      "importance": 1.0134668400496594e-05
    },
    {
      "name": "model.language_model.layers.29.self_attn.o_proj.quant_recipe",
      "importance": 1.6306741827065707e-05
    },
    {
      "name": "model.language_model.layers.32.self_attn.o_proj.quant_recipe",
      "importance": 1.6582119940267148e-05
    },
    {
      "name": "model.language_model.layers.31.self_attn.o_proj.quant_recipe",
      "importance": 1.7082093734188675e-05
    },
    {
      "name": "model.language_model.layers.2.self_attn.o_proj.quant_recipe",
      "importance": 1.7749386870491435e-05
    },
    {
      "name": "model.language_model.layers.25.self_attn.o_proj.quant_recipe",
      "importance": 2.1352330406898545e-05
    },
    {
      "name": "model.language_model.layers.3.self_attn.o_proj.quant_recipe",
      "importance": 2.1785841738619638e-05
    },
    {
      "name": "model.language_model.layers.27.self_attn.o_proj.quant_recipe",
      "importance": 2.2495826215163106e-05
    },
    {
      "name": "model.language_model.layers.30.self_attn.o_proj.quant_recipe",
      "importance": 2.2526705492964538e-05
    },
    {
      "name": "model.language_model.layers.26.self_attn.o_proj.quant_recipe",
      "importance": 2.4117341126839165e-05
    },
    {
      "name": "model.language_model.layers.20.self_attn.o_proj.quant_recipe",
      "importance": 2.5302112703684543e-05
    },
    {
      "name": "model.language_model.layers.17.self_attn.o_proj.quant_recipe",
      "importance": 2.6085949457410607e-05
    },
    {
      "name": "model.language_model.layers.13.self_attn.o_proj.quant_recipe",
      "importance": 2.7204659659219033e-05
    },
    {
      "name": "model.language_model.layers.28.self_attn.o_proj.quant_recipe",
      "importance": 2.7344533691575634e-05
    },
    {
      "name": "model.language_model.layers.18.self_attn.o_proj.quant_recipe",
      "importance": 2.7501244971972483e-05
    },
    {
      "name": "model.language_model.layers.21.self_attn.o_proj.quant_recipe",
      "importance": 2.866190391159762e-05
    },
    {
      "name": "model.language_model.layers.19.self_attn.o_proj.quant_recipe",
      "importance": 2.9029236998212582e-05
    },
    {
      "name": "model.language_model.layers.34.self_attn.o_proj.quant_recipe",
      "importance": 3.097374826666055e-05
    },
    {
      "name": "model.language_model.layers.4.self_attn.o_proj.quant_recipe",
      "importance": 3.3044994665942795e-05
    },
    {
      "name": "model.language_model.layers.11.self_attn.o_proj.quant_recipe",
      "importance": 3.452380678936606e-05
    },
    {
      "name": "model.language_model.layers.16.self_attn.o_proj.quant_recipe",
      "importance": 3.565310476005834e-05
    },
    {
      "name": "model.language_model.layers.24.self_attn.o_proj.quant_recipe",
      "importance": 3.8404190718210884e-05
    },
    {
      "name": "model.language_model.layers.9.self_attn.o_proj.quant_recipe",
      "importance": 4.078883262081945e-05
    },
    {
      "name": "model.language_model.layers.1.self_attn.o_proj.quant_recipe",
      "importance": 4.119380230349634e-05
    },
    {
      "name": "model.language_model.layers.5.self_attn.o_proj.quant_recipe",
      "importance": 4.175558478891617e-05
    },
    {
      "name": "model.language_model.layers.12.self_attn.o_proj.quant_recipe",
      "importance": 4.1906343767550425e-05
    },
    {
      "name": "model.language_model.layers.7.self_attn.o_proj.quant_recipe",
      "importance": 4.251587677117641e-05
    },
    {
      "name": "model.language_model.layers.14.self_attn.o_proj.quant_recipe",
      "importance": 4.451778067959822e-05
    },
    {
      "name": "model.language_model.layers.10.self_attn.o_proj.quant_recipe",
      "importance": 4.47301805479583e-05
    },
    {
      "name": "model.language_model.layers.22.self_attn.o_proj.quant_recipe",
      "importance": 4.717753290606197e-05
    },
    {
      "name": "model.language_model.layers.2.self_attn.q_proj.quant_recipe",
      "importance": 4.800308013841459e-05
    },
    {
      "name": "model.language_model.layers.15.self_attn.o_proj.quant_recipe",
      "importance": 4.9878826075655525e-05
    },
    {
      "name": "model.language_model.layers.1.self_attn.q_proj.quant_recipe",
      "importance": 5.51954801011334e-05
    },
    {
      "name": "model.language_model.layers.35.self_attn.o_proj.quant_recipe",
      "importance": 5.536005505746289e-05
    },
    {
      "name": "model.language_model.layers.23.self_attn.o_proj.quant_recipe",
      "importance": 5.781165600637905e-05
    },
    {
      "name": "model.language_model.layers.8.self_attn.o_proj.quant_recipe",
      "importance": 6.435199929910596e-05
    },
    {
      "name": "model.language_model.layers.3.self_attn.q_proj.quant_recipe",
      "importance": 7.34868021083912e-05
    },
    {
      "name": "model.language_model.layers.12.self_attn.q_proj.quant_recipe",
      "importance": 7.635171829178944e-05
    },
    {
      "name": "model.language_model.layers.20.self_attn.q_proj.quant_recipe",
      "importance": 7.933083998068469e-05
    },
    {
      "name": "model.language_model.layers.33.self_attn.q_proj.quant_recipe",
      "importance": 8.171949741608842e-05
    },
    {
      "name": "model.language_model.layers.17.self_attn.q_proj.quant_recipe",
      "importance": 8.738651706607925e-05
    },
    {
      "name": "model.language_model.layers.29.self_attn.q_proj.quant_recipe",
      "importance": 8.816931165256392e-05
    },
    {
      "name": "model.language_model.layers.4.self_attn.q_proj.quant_recipe",
      "importance": 8.918459377582622e-05
    },
    {
      "name": "model.language_model.layers.13.self_attn.q_proj.quant_recipe",
      "importance": 9.163172632042915e-05
    },
    {
      "name": "model.language_model.layers.16.self_attn.q_proj.quant_recipe",
      "importance": 9.710752237879205e-05
    },
    {
      "name": "model.language_model.layers.18.self_attn.q_proj.quant_recipe",
      "importance": 0.00010349754415983625
    },
    {
      "name": "model.language_model.layers.19.self_attn.q_proj.quant_recipe",
      "importance": 0.00010665617571703478
    },
    {
      "name": "model.language_model.layers.27.self_attn.q_proj.quant_recipe",
      "importance": 0.00010698880117843146
    },
    {
      "name": "model.language_model.layers.31.self_attn.q_proj.quant_recipe",
      "importance": 0.00011006023044046742
    },
    {
      "name": "model.language_model.layers.5.self_attn.q_proj.quant_recipe",
      "importance": 0.00011237741830427694
    },
    {
      "name": "model.language_model.layers.11.self_attn.q_proj.quant_recipe",
      "importance": 0.00011294577302578546
    },
    {
      "name": "model.language_model.layers.32.self_attn.q_proj.quant_recipe",
      "importance": 0.00011373171685136185
    },
    {
      "name": "model.language_model.layers.15.self_attn.q_proj.quant_recipe",
      "importance": 0.00011733550695680606
    },
    {
      "name": "model.language_model.layers.28.self_attn.q_proj.quant_recipe",
      "importance": 0.00012182702357677044
    },
    {
      "name": "model.language_model.layers.30.self_attn.q_proj.quant_recipe",
      "importance": 0.0001229115654268753
    },
    {
      "name": "model.language_model.layers.0.self_attn.o_proj.quant_recipe",
      "importance": 0.00012433590063665179
    },
    {
      "name": "model.language_model.layers.25.self_attn.q_proj.quant_recipe",
      "importance": 0.0001259296655007347
    },
    {
      "name": "model.language_model.layers.6.self_attn.o_proj.quant_recipe",
      "importance": 0.00013715316208617878
    },
    {
      "name": "model.language_model.layers.6.self_attn.q_proj.quant_recipe",
      "importance": 0.00014429849704811204
    },
    {
      "name": "model.language_model.layers.26.self_attn.q_proj.quant_recipe",
      "importance": 0.00015519691612553288
    },
    {
      "name": "model.language_model.layers.24.self_attn.q_proj.quant_recipe",
      "importance": 0.00016431726214705122
    },
    {
      "name": "model.language_model.layers.8.self_attn.q_proj.quant_recipe",
      "importance": 0.00016957324066879664
    },
    {
      "name": "model.language_model.layers.7.self_attn.q_proj.quant_recipe",
      "importance": 0.0001706148292441867
    },
    {
      "name": "model.language_model.layers.34.self_attn.q_proj.quant_recipe",
      "importance": 0.00017387752018294123
    },
    {
      "name": "model.language_model.layers.14.self_attn.q_proj.quant_recipe",
      "importance": 0.0001832663248251265
    },
    {
      "name": "model.language_model.layers.21.self_attn.q_proj.quant_recipe",
      "importance": 0.00019285434098037513
    },
    {
      "name": "model.language_model.layers.10.self_attn.q_proj.quant_recipe",
      "importance": 0.0001929598255401288
    },
    {
      "name": "model.language_model.layers.22.self_attn.q_proj.quant_recipe",
      "importance": 0.00019664229284899193
    },
    {
      "name": "model.language_model.layers.9.self_attn.q_proj.quant_recipe",
      "importance": 0.00020340952312380978
    },
    {
      "name": "model.language_model.layers.23.self_attn.q_proj.quant_recipe",
      "importance": 0.00020492899170676537
    },
    {
      "name": "model.language_model.layers.35.self_attn.q_proj.quant_recipe",
      "importance": 0.0002510994436306646
    },
    {
      "name": "model.language_model.layers.0.self_attn.q_proj.quant_recipe",
      "importance": 0.00036924227026702283
    },
    {
      "name": "model.language_model.layers.33.mlp.down_proj.quant_recipe",
      "importance": 0.0010487482977623586
    },
    {
      "name": "model.language_model.layers.34.mlp.down_proj.quant_recipe",
      "importance": 0.0013042406426393427
    },
    {
      "name": "model.language_model.layers.32.mlp.down_proj.quant_recipe",
      "importance": 0.0017004816472763196
    },
    {
      "name": "model.language_model.layers.31.mlp.down_proj.quant_recipe",
      "importance": 0.0021604772919090465
    },
    {
      "name": "model.language_model.layers.33.mlp.gate_proj.quant_recipe",
      "importance": 0.0024301537559949793
    },
    {
      "name": "model.language_model.layers.30.mlp.down_proj.quant_recipe",
      "importance": 0.002775914268568158
    },
    {
      "name": "model.language_model.layers.35.mlp.down_proj.quant_recipe",
      "importance": 0.002819268047460355
    },
    {
      "name": "model.language_model.layers.29.mlp.down_proj.quant_recipe",
      "importance": 0.003497755475109443
    },
    {
      "name": "model.language_model.layers.32.mlp.gate_proj.quant_recipe",
      "importance": 0.0037106874951859936
    },
    {
      "name": "model.language_model.layers.31.mlp.gate_proj.quant_recipe",
      "importance": 0.004516059620073065
    },
    {
      "name": "model.language_model.layers.30.mlp.gate_proj.quant_recipe",
      "importance": 0.005343278528016526
    },
    {
      "name": "model.language_model.layers.28.mlp.down_proj.quant_recipe",
      "importance": 0.005517322395462543
    },
    {
      "name": "model.language_model.layers.34.mlp.gate_proj.quant_recipe",
      "importance": 0.008049389150983188
    },
    {
      "name": "model.language_model.layers.29.mlp.gate_proj.quant_recipe",
      "importance": 0.008136801785440184
    },
    {
      "name": "model.language_model.layers.27.mlp.down_proj.quant_recipe",
      "importance": 0.009238495375029743
    },
    {
      "name": "model.language_model.layers.28.mlp.gate_proj.quant_recipe",
      "importance": 0.01243322718073614
    },
    {
      "name": "model.language_model.layers.26.mlp.down_proj.quant_recipe",
      "importance": 0.014128082490060478
    },
    {
      "name": "model.language_model.layers.25.mlp.down_proj.quant_recipe",
      "importance": 0.019249645760282874
    },
    {
      "name": "model.language_model.layers.27.mlp.gate_proj.quant_recipe",
      "importance": 0.020910948544042185
    },
    {
      "name": "model.language_model.layers.24.mlp.down_proj.quant_recipe",
      "importance": 0.023389000445604324
    },
    {
      "name": "model.language_model.layers.26.mlp.gate_proj.quant_recipe",
      "importance": 0.0301383092883043
    },
    {
      "name": "model.language_model.layers.23.mlp.down_proj.quant_recipe",
      "importance": 0.03049649891909212
    },
    {
      "name": "lm_head.quant_recipe",
      "importance": 0.031611767946742475
    },
    {
      "name": "model.language_model.layers.25.mlp.gate_proj.quant_recipe",
      "importance": 0.04099291970487684
    },
    {
      "name": "model.language_model.layers.21.mlp.down_proj.quant_recipe",
      "importance": 0.04598381253890693
    },
    {
      "name": "model.language_model.layers.22.mlp.down_proj.quant_recipe",
      "importance": 0.0487591119017452
    },
    {
      "name": "model.language_model.layers.24.mlp.gate_proj.quant_recipe",
      "importance": 0.0529621479799971
    },
    {
      "name": "model.language_model.layers.20.mlp.down_proj.quant_recipe",
      "importance": 0.053387322230264544
    },
    {
      "name": "model.language_model.layers.23.mlp.gate_proj.quant_recipe",
      "importance": 0.06908084871247411
    },
    {
      "name": "model.language_model.layers.22.mlp.gate_proj.quant_recipe",
      "importance": 0.07372195972129703
    },
    {
      "name": "model.language_model.layers.19.mlp.down_proj.quant_recipe",
      "importance": 0.08457813691347837
    },
    {
      "name": "model.language_model.layers.21.mlp.gate_proj.quant_recipe",
      "importance": 0.09051002841442823
    },
    {
      "name": "model.language_model.layers.20.mlp.gate_proj.quant_recipe",
      "importance": 0.11330653913319111
    },
    {
      "name": "model.language_model.layers.18.mlp.down_proj.quant_recipe",
      "importance": 0.12571820430457592
    },
    {
      "name": "model.language_model.layers.17.mlp.down_proj.quant_recipe",
      "importance": 0.15107910428196192
    },
    {
      "name": "model.language_model.layers.19.mlp.gate_proj.quant_recipe",
      "importance": 0.16311313305050135
    },
    {
      "name": "model.language_model.layers.1.mlp.down_proj.quant_recipe",
      "importance": 0.19570928253233433
    },
    {
      "name": "model.language_model.layers.18.mlp.gate_proj.quant_recipe",
      "importance": 0.2281972379423678
    },
    {
      "name": "model.language_model.layers.16.mlp.down_proj.quant_recipe",
      "importance": 0.24369711335748434
    },
    {
      "name": "model.language_model.layers.35.mlp.gate_proj.quant_recipe",
      "importance": 0.3003386161290109
    },
    {
      "name": "model.language_model.layers.2.mlp.down_proj.quant_recipe",
      "importance": 0.3025950836017728
    },
    {
      "name": "model.language_model.layers.11.mlp.down_proj.quant_recipe",
      "importance": 0.32309514470398426
    },
    {
      "name": "model.language_model.layers.17.mlp.gate_proj.quant_recipe",
      "importance": 0.329732745885849
    },
    {
      "name": "model.language_model.layers.8.mlp.down_proj.quant_recipe",
      "importance": 0.34285296499729156
    },
    {
      "name": "model.language_model.layers.7.mlp.down_proj.quant_recipe",
      "importance": 0.3630667105317116
    },
    {
      "name": "model.language_model.layers.15.mlp.down_proj.quant_recipe",
      "importance": 0.38646308705210686
    },
    {
      "name": "model.language_model.layers.12.mlp.down_proj.quant_recipe",
      "importance": 0.4287195485085249
    },
    {
      "name": "model.language_model.layers.10.mlp.down_proj.quant_recipe",
      "importance": 0.43569557555019855
    },
    {
      "name": "model.language_model.layers.9.mlp.down_proj.quant_recipe",
      "importance": 0.43876457773149014
    },
    {
      "name": "model.language_model.layers.3.mlp.down_proj.quant_recipe",
      "importance": 0.4475914239883423
    },
    {
      "name": "model.language_model.layers.14.mlp.down_proj.quant_recipe",
      "importance": 0.4493721257895231
    },
    {
      "name": "model.language_model.layers.16.mlp.gate_proj.quant_recipe",
      "importance": 0.5045877434313297
    },
    {
      "name": "model.language_model.layers.1.mlp.gate_proj.quant_recipe",
      "importance": 0.5066836448386312
    },
    {
      "name": "model.language_model.layers.13.mlp.down_proj.quant_recipe",
      "importance": 0.5381579101085663
    },
    {
      "name": "model.language_model.layers.11.mlp.gate_proj.quant_recipe",
      "importance": 0.5988997286185622
    },
    {
      "name": "model.language_model.layers.6.mlp.down_proj.quant_recipe",
      "importance": 0.6001670248806477
    },
    {
      "name": "model.language_model.layers.13.mlp.gate_proj.quant_recipe",
      "importance": 0.6306649632751942
    },
    {
      "name": "model.language_model.layers.15.mlp.gate_proj.quant_recipe",
      "importance": 0.6791880391538143
    },
    {
      "name": "model.language_model.layers.9.mlp.gate_proj.quant_recipe",
      "importance": 0.6916103232651949
    },
    {
      "name": "model.language_model.layers.8.mlp.gate_proj.quant_recipe",
      "importance": 0.6919713038951159
    },
    {
      "name": "model.language_model.layers.5.mlp.down_proj.quant_recipe",
      "importance": 0.7142941392958164
    },
    {
      "name": "model.language_model.layers.12.mlp.gate_proj.quant_recipe",
      "importance": 0.7206101631745696
    },
    {
      "name": "model.language_model.layers.10.mlp.gate_proj.quant_recipe",
      "importance": 0.7405918603762984
    },
    {
      "name": "model.language_model.layers.0.mlp.gate_proj.quant_recipe",
      "importance": 0.7682000957429409
    },
    {
      "name": "model.language_model.layers.14.mlp.gate_proj.quant_recipe",
      "importance": 0.8000804036855698
    },
    {
      "name": "model.language_model.layers.4.mlp.down_proj.quant_recipe",
      "importance": 0.9745144248008728
    },
    {
      "name": "model.language_model.layers.7.mlp.gate_proj.quant_recipe",
      "importance": 1.0310780983418226
    },
    {
      "name": "model.language_model.layers.6.mlp.gate_proj.quant_recipe",
      "importance": 1.1565511859953403
    },
    {
      "name": "model.language_model.layers.5.mlp.gate_proj.quant_recipe",
      "importance": 1.356670554727316
    },
    {
      "name": "model.language_model.layers.2.mlp.gate_proj.quant_recipe",
      "importance": 1.3884448632597923
    },
    {
      "name": "model.language_model.layers.3.mlp.gate_proj.quant_recipe",
      "importance": 1.8539249747991562
    },
    {
      "name": "model.language_model.layers.4.mlp.gate_proj.quant_recipe",
      "importance": 2.4106449112296104
    },
    {
      "name": "model.language_model.layers.0.mlp.down_proj.quant_recipe",
      "importance": 2.766656205058098
    }
  ]
}