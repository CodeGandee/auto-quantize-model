{
  "scheme": {
    "name": "int8_autoquant_full",
    "auto_quantize_bits": 8.0,
    "auto_quantize_method": "gradient",
    "auto_quantize_score_size": 96,
    "coverage_mode": "full",
    "coverage_fraction": 1.0,
    "quant_formats": [
      "INT8_LM_DEFAULT_CFG"
    ]
  },
  "model": {
    "id": "/workspace/code/auto-quantize-model/models/qwen2_5_vl_3b_instruct/checkpoints/Qwen2.5-VL-3B-Instruct"
  },
  "autoquant_state": {
    "keys": [
      "candidate_stats",
      "best",
      "constraints"
    ],
    "constraints": {
      "effective_bits": 8.0
    },
    "score": 11.235865751874005,
    "is_satisfied": true
  },
  "layer_sensitivity": [
    {
      "layer": "language_model.layers.28.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 6.859986330997344,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.30.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 3.2422646582126617,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.1.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.48075391343445517,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.3.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.14505501161329448,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.35.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.1206384883262217,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.29.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.10191191574267577,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.30.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.06431661499664187,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.2.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.03628334077075124,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.2.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.030678732888191007,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.25.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.01709455196282761,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.3.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.01674746599746868,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.29.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.008982272120192647,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.31.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00827735784696415,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.4.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.007506058376748115,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.1.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.005456341168610379,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.6.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0053757055720780045,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.7.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.004648044268833473,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.5.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.004636600318917772,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.8.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.004609753770637326,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.32.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.004202302225166932,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.9.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0040685226558707654,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.27.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.003849910605822515,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.5.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0037677849613828585,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.4.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0034851808013627306,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.0.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.003247235275921412,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.33.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0029392479773378,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.11.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0027763870893977582,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.28.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0026245885528624058,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.10.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.002621864332468249,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.27.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0023325975780608132,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.15.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.002227400807896629,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.7.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0021505521344806766,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.12.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0020806886968784966,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.34.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.002015164543990977,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.13.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0017610970753594302,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.35.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.001726994105410995,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.18.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0016958255509962328,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.16.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0014210485132934991,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.26.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0011977839603787288,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.14.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0011379958123143297,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.6.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0010891213169088587,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.25.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0010823866978171282,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.19.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0009441748006793205,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.9.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0007667445333936485,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.34.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0007459892713086447,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.10.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0006572739594048471,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.17.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0006303986447164789,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.33.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0005668391113431426,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.8.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0005140773737366544,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.31.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0004756864200317068,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.24.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0004495865559874801,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.22.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00043895517046621535,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.23.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0004275053506717086,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.32.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0004077142029927927,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.20.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0003491010866127908,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.21.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0003432205667195376,
      "size_cost": 11272192.0
    },
    {
      "layer": "language_model.layers.0.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0003347794757075917,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.13.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0002891961171371804,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.12.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0002863878612515691,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.17.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0002756671203769656,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.16.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0002451218624628382,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.11.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0002372495264353347,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.14.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00021394971986410383,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.9.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.000185949390697715,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.23.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00018345676386388732,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.19.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00018274660237693752,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.18.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001788682886854076,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.1.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001750660521224745,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.20.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00017309113673036336,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.8.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00016620444077375396,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.21.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001600814773610182,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.10.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00015248986483129556,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.15.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00014292422974904184,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.33.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00013714729610114773,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.25.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00013667795900573765,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.26.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00013632006994157564,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.27.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00013400681437758521,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.22.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00013327887040759379,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.11.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001289329827613983,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.6.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00012662773039551212,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.15.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001231576740252649,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.30.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001222610664513013,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.12.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00012036058825515283,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.17.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00011785388281282394,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.7.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001166552943914212,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.14.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00011540708652546527,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.31.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00011499620580934788,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.32.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001130038645840159,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.13.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0001092801207391858,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.18.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00010613933162062494,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.20.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00010518658567093553,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.28.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 0.00010512574630183735,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.4.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 9.861822486811889e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.5.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 9.762930963574945e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.3.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 9.287571702998321e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.23.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 9.131897309089254e-05,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.2.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 8.80914750212014e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.24.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 8.78645303146186e-05,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.24.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.826879394201569e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.29.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 7.339248573146051e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.19.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.924555117393538e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.21.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.850088496435092e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.26.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 6.50477220887069e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.0.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.089534508646466e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.16.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 5.9554870546207894e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.22.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 5.116442582675518e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.34.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 3.410812594850654e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.33.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.0447315111814532e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.35.self_attn.q_proj",
      "num_bits": 8.0,
      "sensitivity": 2.9384213235061907e-05,
      "size_cost": 2621440.0
    },
    {
      "layer": "language_model.layers.9.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.1176374502829276e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.30.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.105632358961884e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.0.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 2.0509762379106178e-05,
      "size_cost": 22544384.0
    },
    {
      "layer": "language_model.layers.1.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.575920282448351e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.32.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4486628401755297e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.20.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.4336792276026245e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.3.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3688559818092472e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.24.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.3213346790053038e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.15.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2899406897304289e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.31.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2823946349271864e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.7.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2378565941162378e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.6.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.2008494422843796e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.14.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.1785364165461942e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.28.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.1764208693421097e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.4.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.1432970723035396e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.11.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.1410123931909766e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.18.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.0865580975405464e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.19.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.0637029163262923e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.5.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 1.027334860737028e-05,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.13.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 9.540659704043719e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.26.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 9.001667422126047e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.16.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 8.707193018153703e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.25.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 7.886010905622243e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.8.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 7.831143506109584e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.10.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 7.475688533986613e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.12.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 7.2446512717760925e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.17.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.512116243584387e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.29.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 6.059273744085658e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.27.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.317478098731954e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.2.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 5.040316608528883e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.23.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.797233884801244e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.21.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 4.5533241319617446e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.22.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 3.2926747763895037e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.34.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.935374894263987e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "language_model.layers.35.self_attn.o_proj",
      "num_bits": 8.0,
      "sensitivity": 2.8872676267610586e-06,
      "size_cost": 2097152.0
    },
    {
      "layer": "visual.patch_embed.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 752640.0
    },
    {
      "layer": "visual.blocks.0.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.0.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.0.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.0.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.1.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.1.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.1.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.1.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.2.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.2.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.2.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.2.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.3.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.3.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.3.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.3.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.4.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.4.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.4.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.4.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.5.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.5.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.5.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.5.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.6.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.6.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.6.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.6.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.7.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.7.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.7.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.7.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.8.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.8.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.8.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.8.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.9.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.9.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.9.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.9.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.10.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.10.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.10.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.10.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.11.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.11.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.11.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.11.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.12.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.12.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.12.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.12.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.13.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.13.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.13.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.13.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.14.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.14.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.14.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.14.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.15.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.15.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.15.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.15.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.16.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.16.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.16.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.16.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.17.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.17.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.17.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.17.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.18.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.18.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.18.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.18.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.19.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.19.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.19.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.19.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.20.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.20.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.20.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.20.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.21.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.21.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.21.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.21.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.22.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.22.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.22.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.22.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.23.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.23.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.23.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.23.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.24.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.24.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.24.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.24.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.25.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.25.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.25.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.25.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.26.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.26.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.26.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.26.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.27.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.27.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.27.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.27.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.28.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.28.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.28.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.28.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.29.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.29.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.29.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.29.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.30.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.30.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.30.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.30.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.blocks.31.attn.qkv",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2457600.0
    },
    {
      "layer": "visual.blocks.31.attn.proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 819200.0
    },
    {
      "layer": "visual.blocks.31.mlp.gate_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 4377600.0
    },
    {
      "layer": "visual.blocks.31.mlp.down_proj",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 2188800.0
    },
    {
      "layer": "visual.merger.mlp.0",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 13107200.0
    },
    {
      "layer": "visual.merger.mlp.2",
      "num_bits": 8.0,
      "sensitivity": 0.0,
      "size_cost": 5242880.0
    }
  ]
}