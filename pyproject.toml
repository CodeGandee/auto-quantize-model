[project]
authors = [{name = "igamenovoer", email = "igamenovoer@xx.com"}]
dependencies = [
  "onnx>=1.20.0,<2",
  "neural-compressor>=2.4.1,<3",
  "nvidia-modelopt>=0.39.0,<0.40",
  "onnx-graphsurgeon>=0.5.8,<0.6",
  "mdutils>=1.8.1,<2",
  "imageio>=2.37.2,<3",
  "polygraphy>=0.49.26,<0.50",
  "onnxruntime-tools>=1.7.0,<2",
  "modelscope>=1.32.0,<2",
  "transformers",
  "accelerate",
  "qwen-vl-utils[decord]==0.0.8", "requests>=2.28.1,<3", "datasets>=2.19.1,<3", "addict>=2.4.0,<3", "diffusers>=0.35.2,<0.36",
]
name = "auto-quantize-model"
requires-python = ">= 3.11, < 3.13"
version = "0.1.0"

[build-system]
build-backend = "hatchling.build"
requires = ["hatchling"]

[tool.pixi.workspace]
channels = ["conda-forge", "nvidia"]
platforms = ["linux-64"]

[tool.pixi.pypi-dependencies]
auto_quantize_model = { path = ".", editable = true }
ultralytics = "*"
torch = "*"
torchvision = "*"
transformers = "*"
accelerate = "*"
diffusers = "*"
safetensors = "*"
onnxruntime-gpu = "*"
cupy-cuda12x = "*"
pip = "*"
supervision = "*"
scipy = "*"
opencv-python = "*"
imageio = "*"
attrs = "*"
omegaconf = "*"
hydra-core = "*"
mdutils = "*"
mkdocs-material = "*"
ruff = "*"
mypy = "*"
pytest = "*"
click = "*"
rich = "*"
pandas = "*"
huggingface-hub = "*"
py-cpuinfo = "*"

[tool.pixi.pypi-options]
index-url = "https://pypi.org/simple"
# Use official PyTorch wheels with CUDA 12.4 (<= 12.6 as requested)
extra-index-urls = ["https://download.pytorch.org/whl/cu124"]

[tool.pixi.activation.env]
LD_LIBRARY_PATH = "/usr/lib/x86_64-linux-gnu:${LD_LIBRARY_PATH}"
PATH = "/opt/tensorrt/bin:${PATH}"

[tool.pixi.tasks]
setup-tensorrt = "env NVIDIA_TENSORRT_DISABLE_INTERNAL_PIP=0 python -m pip install tensorrt==10.7.0 --extra-index-url https://pypi.nvidia.com"

[tool.pixi.dependencies]
python = "3.12.*"
