# pei-docker configuration file for machine learning development environment in CN
# with gpu support

# all paths are relative to /installation directory

stage_1:
  # input/output image settings
  image:
    base: nvcr.io/nvidia/tensorrt:24.12-py3
    output: auto-quantize:stage-1

  # ssh settings
  ssh:
    enable: true

    # port in container, if given, this port WILL be set inside container as SSH port
    port: 22

    # mapped port on host machine, if given, this port will be mapped to the container SSH port
    host_port: 13444

    # ssh users, the key is user name, value is user info
    users:
      me:
        password: '123456'
        uid: 3100
        gid: 1100
        pubkey_file: ~
        privkey_file: ~

      root:
        # you can configure root user here
        password: root

  # proxy settings, by default, NOT enabled
  # to enable proxy, set enable_globally to true
  # inside the container, the proxy will accessed as http://{address}:{port}
  # note that whether the proxy is used or not depends on the applications
  proxy:
    address: host.docker.internal # default value, this will map to the host machine
    port: 7890 # if address==host.docker.internal, this will be the proxy port on host machine
    enable_globally: true # enable proxy for all shell commands during build and run?
    remove_after_build: true # remove global proxy after build?

  device:
    type: gpu

  # apt settings
  apt:
    # replace the default apt source with a custom one, use empty string to disable this
    # repo_source: 'stage-1/system/apt/ubuntu-22.04-tsinghua-x64.list'
    # special values that refer to well known apt sources:
    # 'tuna' : 'http://mirrors.tuna.tsinghua.edu.cn/ubuntu/'
    # 'aliyun' : 'http://mirrors.aliyun.com/ubuntu/'
    # '163' : 'http://mirrors.163.com/ubuntu/'
    # 'ustc' : 'http://mirrors.ustc.edu.cn/ubuntu/'
    # 'cn' : 'http://cn.archive.ubuntu.com/ubuntu/
    repo_source: 'aliyun'
    keep_repo_after_build: true # keep the apt source file after build?

  # custom scripts
  custom:
    # scripts run during build
    # Scripts can include parameters: 'script.sh --param1=value1 --param2="value with spaces"'
    on_build:
    # ngc-specific fixes
    - "stage-1/system/ngc/fix-shinit.sh"

    # commonly used development tools
    - 'stage-1/custom/install-dev-tools.sh'

    # vision-specific development tools
    - 'stage-1/system/vision-dev/install-vision-dev.bash' # install vision development tools

stage_2:

  # input/output image settings
  image:
    output: auto-quantize:stage-2

  device:
    type: gpu

  # storage configurations
  # use 'auto-volume' to automatically create a docker volume for the dynamic storage
  storage:
    app:
      type: auto-volume # auto-volume, manual-volume, host, image

    data:
      type: auto-volume

    workspace:
      type: auto-volume

  # mount external volumes to container
  # the volumes can be given any names, mounted anywhere
  # the volume type cannot be 'image', or otherwise it will be ignored
  mount:
    home_me:
      type: auto-volume # auto-volume, manual-volume, host
      dst_path: /home/me
      host_path: null # when type=host, this points to the host directory to be mounted
      volume_name: null # when type=manual-volume, this is the name of the manually created docker volume
    cache_disk:
      type: host
      dst_path: /pkg-cache
      host_path: /data2/huangzhe/docker-works/pkg-cache
    data2:
      type: host
      dst_path: /data2
      host_path: /data2
    nfs_filesystem:
      type: host
      dst_path: /nfs
      host_path: /nfs

  custom:
    # scripts run during build
    # Scripts can include parameters: 'script.sh --param1=value1 --param2="value with spaces"'
    on_build:
    # install pixi, a lightweight python package manager
    - 'stage-2/system/pixi/install-pixi.bash --pypi-repo tuna --conda-repo tuna --user me --cache-dir=/pkg-cache/pixi'

    # install uv
    - 'stage-1/system/uv/install-uv.sh --pypi-repo tuna --user me'

    # install nodejs for codex and claude code
    - 'stage-2/system/nodejs/install-nvm-nodejs.sh --with-cn-mirror --user me'

    # install codex
    - 'stage-2/system/codex-cli/install-codex-cli.sh --user me'

    # install claude code
    - 'stage-2/system/claude-code/install-claude-code.sh --user me'
